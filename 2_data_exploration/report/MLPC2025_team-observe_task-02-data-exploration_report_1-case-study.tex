
\section{Case Study}
\label{sec:Case Study}

To find 2 interesting records that were edited by multiple annotators, 
we first looked in ``metadata.csv'' to see which files had more than one annotator. 
This resulted in a list of 149 files. 
We then looked at the ``metadata_title_embeddings.npz'' and the ``metadata_keywords_embeddings.npz'' in order to be able to draw some conclusions. 
At the same time, we also checked the standardization of the embedding. 
The approach was that files with very clear embedding (target: 1.0 in one place) lead to very clear annotations. 
An important assumption here is the correctness and accuracy of the titles and keywords. 


\subsection{Identify similarities or differences between temporal and textual annotations from different annotators.}
\label{sec:Case Study:a}



\subsection{To what extent do the annotations rely on or deviate from keywords and textual descriptions in the audioâ€™s metadata?}
\label{sec:Case Study:b}



\subsection{Was the temporal and text annotations done according to the task description?}
\label{sec:Case Study:c}




