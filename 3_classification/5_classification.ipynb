{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:00:06.684201Z",
     "start_time": "2025-05-19T10:00:06.680099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from random import Random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import sklearn\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import umap.umap_ as umap\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ],
   "id": "b9446b9c9534019a",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:00:06.726342Z",
     "start_time": "2025-05-19T10:00:06.723286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Path to the .npz file\n",
    "DATASET_PATH = \"../MLPC2025_classification\"\n",
    "\n",
    "ANNOTATIONS_PATH = DATASET_PATH + \"/annotations.csv\"\n",
    "#ANNOTATIONS_TEXT_EMBEDDINGS_PATH = DATASET_PATH + \"/annotations_text_embeddings.npz\"\n",
    "\n",
    "METADATA_PATH = DATASET_PATH + \"/metadata.csv\"\n",
    "#METADATA_TITLE_EMBEDDINGS_PATH = DATASET_PATH + \"/metadata_title_embeddings.npz\"\n",
    "#METADATA_KEYWORDS_EMBEDDINGS_PATH = DATASET_PATH + \"/metadata_keywords_embeddings.npz\"\n",
    "\n",
    "AUDIO_PATHS = DATASET_PATH + \"/audio\"\n",
    "AUDIO_FEATURES_PATHS = DATASET_PATH + \"/audio_features\"\n",
    "\n",
    "LABELS_PATH = DATASET_PATH + \"/labels\""
   ],
   "id": "6c0431f14c6ff38b",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:00:06.845301Z",
     "start_time": "2025-05-19T10:00:06.765820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "annotations = pd.read_csv(ANNOTATIONS_PATH)\n",
    "annotations.head()"
   ],
   "id": "2eadf99a822dc0bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     task_id    filename                                          annotator  \\\n",
       "0  161976549  117126.mp3  1145579747015607221221744067969991550764671773...   \n",
       "1  161976549  117126.mp3  1145579747015607221221744067969991550764671773...   \n",
       "2  161976550  118234.mp3  5022633589939139634134314703519782680423201448...   \n",
       "3  161976550  118234.mp3  5022633589939139634134314703519782680423201448...   \n",
       "4  161976551  119173.mp3  8105077500224920444298835829881210427871190692...   \n",
       "\n",
       "                                                text      onset     offset  \\\n",
       "0  An alarm is ringing loudly and repeatedly nearby.   0.000000  10.503064   \n",
       "1             An alarm is ringing repeatedly nearby.  12.514616  23.048000   \n",
       "2            An alarm clock is beeping continuously.   0.000000  13.414880   \n",
       "3            An alarm clock is beeping continuously.  15.134252  28.492000   \n",
       "4     A car alarm sounds loudly in a steady pattern.   0.000000  20.065604   \n",
       "\n",
       "       time                                   original_caption  \\\n",
       "0   345.033     Raw loud alarm sound repeatedly ringing nearby   \n",
       "1   345.033        Clean alarm sound repeatedly ringing nearby   \n",
       "2   919.016                    Alarm clock beeping continuesly   \n",
       "3   919.016                    Alarm clock beeping continuesly   \n",
       "4  2162.620  a car alarm sounds loudly in a steady pattern ...   \n",
       "\n",
       "                categories  \n",
       "0                ['Alarm']  \n",
       "1                ['Alarm']  \n",
       "2  ['Alarm', 'Beep/Bleep']  \n",
       "3  ['Alarm', 'Beep/Bleep']  \n",
       "4         ['Alarm', 'Car']  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>annotator</th>\n",
       "      <th>text</th>\n",
       "      <th>onset</th>\n",
       "      <th>offset</th>\n",
       "      <th>time</th>\n",
       "      <th>original_caption</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161976549</td>\n",
       "      <td>117126.mp3</td>\n",
       "      <td>1145579747015607221221744067969991550764671773...</td>\n",
       "      <td>An alarm is ringing loudly and repeatedly nearby.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.503064</td>\n",
       "      <td>345.033</td>\n",
       "      <td>Raw loud alarm sound repeatedly ringing nearby</td>\n",
       "      <td>['Alarm']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161976549</td>\n",
       "      <td>117126.mp3</td>\n",
       "      <td>1145579747015607221221744067969991550764671773...</td>\n",
       "      <td>An alarm is ringing repeatedly nearby.</td>\n",
       "      <td>12.514616</td>\n",
       "      <td>23.048000</td>\n",
       "      <td>345.033</td>\n",
       "      <td>Clean alarm sound repeatedly ringing nearby</td>\n",
       "      <td>['Alarm']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>161976550</td>\n",
       "      <td>118234.mp3</td>\n",
       "      <td>5022633589939139634134314703519782680423201448...</td>\n",
       "      <td>An alarm clock is beeping continuously.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.414880</td>\n",
       "      <td>919.016</td>\n",
       "      <td>Alarm clock beeping continuesly</td>\n",
       "      <td>['Alarm', 'Beep/Bleep']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161976550</td>\n",
       "      <td>118234.mp3</td>\n",
       "      <td>5022633589939139634134314703519782680423201448...</td>\n",
       "      <td>An alarm clock is beeping continuously.</td>\n",
       "      <td>15.134252</td>\n",
       "      <td>28.492000</td>\n",
       "      <td>919.016</td>\n",
       "      <td>Alarm clock beeping continuesly</td>\n",
       "      <td>['Alarm', 'Beep/Bleep']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161976551</td>\n",
       "      <td>119173.mp3</td>\n",
       "      <td>8105077500224920444298835829881210427871190692...</td>\n",
       "      <td>A car alarm sounds loudly in a steady pattern.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.065604</td>\n",
       "      <td>2162.620</td>\n",
       "      <td>a car alarm sounds loudly in a steady pattern ...</td>\n",
       "      <td>['Alarm', 'Car']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:00:06.917228Z",
     "start_time": "2025-05-19T10:00:06.906186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove unnecessary columns for this task\n",
    "annotations = annotations.drop(columns=['task_id'])\n",
    "annotations['original_index'] = annotations.index\n",
    "annotations.head()"
   ],
   "id": "97b94e60b45e3b4d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     filename                                          annotator  \\\n",
       "0  117126.mp3  1145579747015607221221744067969991550764671773...   \n",
       "1  117126.mp3  1145579747015607221221744067969991550764671773...   \n",
       "2  118234.mp3  5022633589939139634134314703519782680423201448...   \n",
       "3  118234.mp3  5022633589939139634134314703519782680423201448...   \n",
       "4  119173.mp3  8105077500224920444298835829881210427871190692...   \n",
       "\n",
       "                                                text      onset     offset  \\\n",
       "0  An alarm is ringing loudly and repeatedly nearby.   0.000000  10.503064   \n",
       "1             An alarm is ringing repeatedly nearby.  12.514616  23.048000   \n",
       "2            An alarm clock is beeping continuously.   0.000000  13.414880   \n",
       "3            An alarm clock is beeping continuously.  15.134252  28.492000   \n",
       "4     A car alarm sounds loudly in a steady pattern.   0.000000  20.065604   \n",
       "\n",
       "       time                                   original_caption  \\\n",
       "0   345.033     Raw loud alarm sound repeatedly ringing nearby   \n",
       "1   345.033        Clean alarm sound repeatedly ringing nearby   \n",
       "2   919.016                    Alarm clock beeping continuesly   \n",
       "3   919.016                    Alarm clock beeping continuesly   \n",
       "4  2162.620  a car alarm sounds loudly in a steady pattern ...   \n",
       "\n",
       "                categories  original_index  \n",
       "0                ['Alarm']               0  \n",
       "1                ['Alarm']               1  \n",
       "2  ['Alarm', 'Beep/Bleep']               2  \n",
       "3  ['Alarm', 'Beep/Bleep']               3  \n",
       "4         ['Alarm', 'Car']               4  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>annotator</th>\n",
       "      <th>text</th>\n",
       "      <th>onset</th>\n",
       "      <th>offset</th>\n",
       "      <th>time</th>\n",
       "      <th>original_caption</th>\n",
       "      <th>categories</th>\n",
       "      <th>original_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117126.mp3</td>\n",
       "      <td>1145579747015607221221744067969991550764671773...</td>\n",
       "      <td>An alarm is ringing loudly and repeatedly nearby.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.503064</td>\n",
       "      <td>345.033</td>\n",
       "      <td>Raw loud alarm sound repeatedly ringing nearby</td>\n",
       "      <td>['Alarm']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117126.mp3</td>\n",
       "      <td>1145579747015607221221744067969991550764671773...</td>\n",
       "      <td>An alarm is ringing repeatedly nearby.</td>\n",
       "      <td>12.514616</td>\n",
       "      <td>23.048000</td>\n",
       "      <td>345.033</td>\n",
       "      <td>Clean alarm sound repeatedly ringing nearby</td>\n",
       "      <td>['Alarm']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118234.mp3</td>\n",
       "      <td>5022633589939139634134314703519782680423201448...</td>\n",
       "      <td>An alarm clock is beeping continuously.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.414880</td>\n",
       "      <td>919.016</td>\n",
       "      <td>Alarm clock beeping continuesly</td>\n",
       "      <td>['Alarm', 'Beep/Bleep']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118234.mp3</td>\n",
       "      <td>5022633589939139634134314703519782680423201448...</td>\n",
       "      <td>An alarm clock is beeping continuously.</td>\n",
       "      <td>15.134252</td>\n",
       "      <td>28.492000</td>\n",
       "      <td>919.016</td>\n",
       "      <td>Alarm clock beeping continuesly</td>\n",
       "      <td>['Alarm', 'Beep/Bleep']</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119173.mp3</td>\n",
       "      <td>8105077500224920444298835829881210427871190692...</td>\n",
       "      <td>A car alarm sounds loudly in a steady pattern.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.065604</td>\n",
       "      <td>2162.620</td>\n",
       "      <td>a car alarm sounds loudly in a steady pattern ...</td>\n",
       "      <td>['Alarm', 'Car']</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:00:07.081556Z",
     "start_time": "2025-05-19T10:00:07.002205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metadata = pd.read_csv(METADATA_PATH)\n",
    "metadata.head()"
   ],
   "id": "78e9137d94de8525",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     filename                                           keywords  \\\n",
       "0  321771.mp3      Interior, AMB, Italy, Distant, Speech, Reverb   \n",
       "1  451371.mp3  kids, throaty, crowd, India, distant, traffic,...   \n",
       "2  199414.mp3                           broadcast, speech, radio   \n",
       "3  410952.mp3            loop2017, atmos, dolby, speech, ableton   \n",
       "4  203908.mp3  dr-40, project, speech, student, italian, reci...   \n",
       "\n",
       "   freesound_id                                         sound_link  \\\n",
       "0        321771  https://freesound.org/people/Skjor1/sounds/321...   \n",
       "1        451371  https://freesound.org/people/kyles/sounds/451371/   \n",
       "2        199414  https://freesound.org/people/martinimeniscus/s...   \n",
       "3        410952  https://freesound.org/people/lietoofine/sounds...   \n",
       "4        203908  https://freesound.org/people/s9ames/sounds/203...   \n",
       "\n",
       "      manufacturer                                            license  \\\n",
       "0           Skjor1  http://creativecommons.org/publicdomain/zero/1.0/   \n",
       "1            kyles  http://creativecommons.org/publicdomain/zero/1.0/   \n",
       "2  martinimeniscus  http://creativecommons.org/publicdomain/zero/1.0/   \n",
       "3       lietoofine       https://creativecommons.org/licenses/by/4.0/   \n",
       "4           s9ames        http://creativecommons.org/licenses/by/3.0/   \n",
       "\n",
       "                                               title  \\\n",
       "0  Interior Ambience + Distant Reverberant Speech...   \n",
       "1  election rally crowd and speech with distant t...   \n",
       "2      Old Radio Speech Background, higher FF125.aif   \n",
       "3                             dolby atmos speech.wav   \n",
       "4                            bologna speech Italian2   \n",
       "\n",
       "                                         description  num_downloads  \\\n",
       "0  Interior Ambience + Distant Reverberant Speech...            120   \n",
       "1  election rally crowd and speech with distant t...            122   \n",
       "2  Background noise for an old radio broadcast sp...            391   \n",
       "3                       dolby atmos speech @Loop2017            193   \n",
       "4  recorded with a tascam dr-40 in a sound studio...            526   \n",
       "\n",
       "                geotag  start_time_s  end_time_s  \n",
       "0                  NaN         5.200      27.179  \n",
       "1                  NaN       120.800     144.984  \n",
       "2                  NaN       102.003     130.921  \n",
       "3  52.479543 13.500279        31.330      54.021  \n",
       "4                  NaN        29.200      45.689  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>keywords</th>\n",
       "      <th>freesound_id</th>\n",
       "      <th>sound_link</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>license</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>num_downloads</th>\n",
       "      <th>geotag</th>\n",
       "      <th>start_time_s</th>\n",
       "      <th>end_time_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321771.mp3</td>\n",
       "      <td>Interior, AMB, Italy, Distant, Speech, Reverb</td>\n",
       "      <td>321771</td>\n",
       "      <td>https://freesound.org/people/Skjor1/sounds/321...</td>\n",
       "      <td>Skjor1</td>\n",
       "      <td>http://creativecommons.org/publicdomain/zero/1.0/</td>\n",
       "      <td>Interior Ambience + Distant Reverberant Speech...</td>\n",
       "      <td>Interior Ambience + Distant Reverberant Speech...</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.200</td>\n",
       "      <td>27.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>451371.mp3</td>\n",
       "      <td>kids, throaty, crowd, India, distant, traffic,...</td>\n",
       "      <td>451371</td>\n",
       "      <td>https://freesound.org/people/kyles/sounds/451371/</td>\n",
       "      <td>kyles</td>\n",
       "      <td>http://creativecommons.org/publicdomain/zero/1.0/</td>\n",
       "      <td>election rally crowd and speech with distant t...</td>\n",
       "      <td>election rally crowd and speech with distant t...</td>\n",
       "      <td>122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.800</td>\n",
       "      <td>144.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199414.mp3</td>\n",
       "      <td>broadcast, speech, radio</td>\n",
       "      <td>199414</td>\n",
       "      <td>https://freesound.org/people/martinimeniscus/s...</td>\n",
       "      <td>martinimeniscus</td>\n",
       "      <td>http://creativecommons.org/publicdomain/zero/1.0/</td>\n",
       "      <td>Old Radio Speech Background, higher FF125.aif</td>\n",
       "      <td>Background noise for an old radio broadcast sp...</td>\n",
       "      <td>391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.003</td>\n",
       "      <td>130.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>410952.mp3</td>\n",
       "      <td>loop2017, atmos, dolby, speech, ableton</td>\n",
       "      <td>410952</td>\n",
       "      <td>https://freesound.org/people/lietoofine/sounds...</td>\n",
       "      <td>lietoofine</td>\n",
       "      <td>https://creativecommons.org/licenses/by/4.0/</td>\n",
       "      <td>dolby atmos speech.wav</td>\n",
       "      <td>dolby atmos speech @Loop2017</td>\n",
       "      <td>193</td>\n",
       "      <td>52.479543 13.500279</td>\n",
       "      <td>31.330</td>\n",
       "      <td>54.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203908.mp3</td>\n",
       "      <td>dr-40, project, speech, student, italian, reci...</td>\n",
       "      <td>203908</td>\n",
       "      <td>https://freesound.org/people/s9ames/sounds/203...</td>\n",
       "      <td>s9ames</td>\n",
       "      <td>http://creativecommons.org/licenses/by/3.0/</td>\n",
       "      <td>bologna speech Italian2</td>\n",
       "      <td>recorded with a tascam dr-40 in a sound studio...</td>\n",
       "      <td>526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.200</td>\n",
       "      <td>45.689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:00:07.210268Z",
     "start_time": "2025-05-19T10:00:07.203843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove unnecessary columns for this task\n",
    "metadata = metadata.drop(columns=['freesound_id', 'sound_link', 'manufacturer', 'license', 'num_downloads', 'geotag', 'start_time_s', 'end_time_s'])\n",
    "metadata.head()"
   ],
   "id": "32766047cbbd396e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     filename                                           keywords  \\\n",
       "0  321771.mp3      Interior, AMB, Italy, Distant, Speech, Reverb   \n",
       "1  451371.mp3  kids, throaty, crowd, India, distant, traffic,...   \n",
       "2  199414.mp3                           broadcast, speech, radio   \n",
       "3  410952.mp3            loop2017, atmos, dolby, speech, ableton   \n",
       "4  203908.mp3  dr-40, project, speech, student, italian, reci...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Interior Ambience + Distant Reverberant Speech...   \n",
       "1  election rally crowd and speech with distant t...   \n",
       "2      Old Radio Speech Background, higher FF125.aif   \n",
       "3                             dolby atmos speech.wav   \n",
       "4                            bologna speech Italian2   \n",
       "\n",
       "                                         description  \n",
       "0  Interior Ambience + Distant Reverberant Speech...  \n",
       "1  election rally crowd and speech with distant t...  \n",
       "2  Background noise for an old radio broadcast sp...  \n",
       "3                       dolby atmos speech @Loop2017  \n",
       "4  recorded with a tascam dr-40 in a sound studio...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>keywords</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321771.mp3</td>\n",
       "      <td>Interior, AMB, Italy, Distant, Speech, Reverb</td>\n",
       "      <td>Interior Ambience + Distant Reverberant Speech...</td>\n",
       "      <td>Interior Ambience + Distant Reverberant Speech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>451371.mp3</td>\n",
       "      <td>kids, throaty, crowd, India, distant, traffic,...</td>\n",
       "      <td>election rally crowd and speech with distant t...</td>\n",
       "      <td>election rally crowd and speech with distant t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199414.mp3</td>\n",
       "      <td>broadcast, speech, radio</td>\n",
       "      <td>Old Radio Speech Background, higher FF125.aif</td>\n",
       "      <td>Background noise for an old radio broadcast sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>410952.mp3</td>\n",
       "      <td>loop2017, atmos, dolby, speech, ableton</td>\n",
       "      <td>dolby atmos speech.wav</td>\n",
       "      <td>dolby atmos speech @Loop2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203908.mp3</td>\n",
       "      <td>dr-40, project, speech, student, italian, reci...</td>\n",
       "      <td>bologna speech Italian2</td>\n",
       "      <td>recorded with a tascam dr-40 in a sound studio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Idea for splitting the data:\n",
    "\n",
    "Use some fixed percentages for training, validation, and test sets (e.g., 70% training, 15% validation, 15% test).\n",
    "Then, for each label, ensure that the same percentage of files is allocated to each set. This way, you maintain the label distribution across all sets.\n",
    "\n",
    "Additionally, some resampling (e.g. SMOTE), undersampling (e.g. RUS, TOMEK) or class weighting techniques can be applied to maintain balance during training."
   ],
   "id": "151c42fceaed2691"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:00:07.451882Z",
     "start_time": "2025-05-19T10:00:07.442981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AudioClassificationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, audio_features_subset, return_snippets, context_length, testing, testing_percentage):\n",
    "        \"\"\"\n",
    "        data_dir: Path to the dataset directory\n",
    "        audio_features_subset: List of audio features to be used\n",
    "        return_snippets: If False, return whole files, if True, return snippets of size context_length\n",
    "        context_length: Length of the snippets to be returned (ideally uneven number)\n",
    "        testing: If True, use a small subset of the audio files for testing\n",
    "        \"\"\"\n",
    "\n",
    "        self.return_snippets = return_snippets\n",
    "        self.context_length = context_length\n",
    "\n",
    "        audio_path = os.path.join(data_dir, 'audio')\n",
    "\n",
    "        # For testing purposes, use a smaller subset of the audio files (just copy some audio files from the audio directory\n",
    "        # to a new directory at the same level)\n",
    "        #audio_path = os.path.join(data_dir, 'audio_subset_test')\n",
    "\n",
    "        self.audio_file_basenames = [os.path.splitext(os.path.basename(name))[0] for name in os.listdir(audio_path) if name.endswith('.mp3')]\n",
    "        if testing:\n",
    "            testing_count = int(len(self.audio_file_basenames) * testing_percentage)\n",
    "            self.audio_file_basenames = self.audio_file_basenames[:testing_count] # Use only a small subset of the audio files for testing purposes\n",
    "        \n",
    "        \n",
    "        self.audio_file_features = []\n",
    "        self.audio_file_labels = []\n",
    "\n",
    "        for audio_file_idx, audio_file_basename in enumerate(tqdm(self.audio_file_basenames)):\n",
    "\n",
    "            # Remove unwanted features and store remaining features\n",
    "            audio_features_dict = dict(np.load(os.path.join(data_dir, 'audio_features', audio_file_basename + '.npz')))\n",
    "            audio_features = [audio_features_dict[wanted_feature] for wanted_feature in audio_features_subset]\n",
    "\n",
    "            n_frames = audio_features[0].shape[0]\n",
    "\n",
    "            # store whole file at once\n",
    "            if not self.return_snippets:\n",
    "                self.audio_file_features.append(audio_features)\n",
    "            # store single snippets\n",
    "            else:\n",
    "                # Pad so that edge-frames have context\n",
    "                padding = ((context_length//2, context_length//2), (0, 0))\n",
    "                audio_features = [np.pad(array=feature, pad_width=padding, mode='constant', constant_values=0) for feature in audio_features]\n",
    "\n",
    "                for frame_idx in range(n_frames):\n",
    "                    frame_features = [audio_feature[frame_idx:frame_idx + context_length] for audio_feature in audio_features]\n",
    "                    self.audio_file_features.append((audio_file_idx, frame_idx, frame_features))\n",
    "\n",
    "            # Store labels\n",
    "            audio_labels_dict = dict(np.load(os.path.join(data_dir, 'labels', audio_file_basename + '_labels.npz')))\n",
    "\n",
    "            n_labels = len(audio_labels_dict.keys())\n",
    "            file_labels = np.zeros((n_frames, n_labels))\n",
    "            for i, (label_name, label_values) in enumerate(audio_labels_dict.items()):\n",
    "\n",
    "                # If there are multiple label sets -> multiple annotators\n",
    "                if label_values.shape[1] != 1:\n",
    "                    # Like discussed in the exercise class, we choose one at random\n",
    "                    label_values = label_values[:, np.random.randint(0, label_values.shape[1]), np.newaxis]\n",
    "\n",
    "                file_labels[:, i] = label_values[:, 0]\n",
    "\n",
    "            # store labels for whole file at once\n",
    "            if not self.return_snippets:\n",
    "                self.audio_file_labels.append(file_labels)\n",
    "            # store labels for single snippets\n",
    "            else:\n",
    "                for frame_idx, frame_labels in enumerate(file_labels):\n",
    "                    self.audio_file_labels.append((audio_file_idx, frame_idx, frame_labels))\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.audio_file_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if not self.return_snippets:\n",
    "            return self.audio_file_basenames[idx], self.audio_file_features[idx], self.audio_file_labels[idx]\n",
    "        else:\n",
    "            file_idx, frame_idx, frame_features = self.audio_file_features[idx]\n",
    "            file_idx, frame_idx, frame_labels = self.audio_file_labels[idx]\n",
    "            return file_idx, self.audio_file_basenames[file_idx], frame_idx, frame_features, frame_labels"
   ],
   "id": "8bac6543901df80",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:03:04.768401Z",
     "start_time": "2025-05-19T10:00:07.643448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_labels = ['Airplane', 'Alarm', 'Beep/Bleep', 'Bell', 'Bicycle', 'Bird Chirp', 'Bus', 'Car', 'Cat Meow', 'Chainsaw', 'Clapping', 'Cough', 'Cow Moo', 'Cowbell', 'Crying', 'Dog Bark', 'Doorbell', 'Drip', 'Drums', 'Fire', 'Footsteps', 'Guitar', 'Hammer', 'Helicopter', 'Hiccup', 'Horn Honk', 'Horse Neigh', 'Insect Buzz', 'Jackhammer', 'Laughter', 'Lawn Mower', 'Motorcycle', 'Piano', 'Pig Oink', 'Power Drill', 'Power Saw', 'Rain', 'Rooster Crow', 'Saxophone', 'Sewing Machine', 'Sheep/Goat Bleat', 'Ship/Boat', 'Shout', 'Singing', 'Siren', 'Sneeze', 'Snoring', 'Speech', 'Stream/River', 'Thunder', 'Train', 'Truck', 'Trumpet', 'Vacuum Cleaner', 'Violin', 'Washing Machine', 'Waves', 'Wind']\n",
    "\n",
    "all_features = ['embeddings', 'melspectrogram', 'mfcc', 'mfcc_delta', 'mfcc_delta2', 'flatness', 'centroid', 'flux', 'energy', 'power', 'bandwidth', 'contrast', 'zerocrossingrate']\n",
    "\n",
    "data = AudioClassificationDataset(\n",
    "    data_dir = DATASET_PATH,\n",
    "    audio_features_subset = ['embeddings', 'melspectrogram', 'mfcc', 'contrast'],\n",
    "    return_snippets = True,\n",
    "    context_length = 1,\n",
    "    testing = False, # Set to False for full dataset\n",
    "    testing_percentage = 0.1\n",
    ")\n",
    "print(f\"Dataset size: {len(data)}\")"
   ],
   "id": "facfd9e524e0c807",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8230/8230 [02:43<00:00, 50.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1538577\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:03:04.816306Z",
     "start_time": "2025-05-19T10:03:04.807307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"This is what the data looks like:\")\n",
    "for i, example in enumerate(data):\n",
    "    if not data.return_snippets:\n",
    "        audio_name, features, labels = example\n",
    "        print(f\"Name: {audio_name}, Feature dim: {[f.shape for f in features]}, Label dim: {labels.shape}\")\n",
    "    elif data.return_snippets:\n",
    "        file_idx, audio_name, frame_idx, features, labels = example\n",
    "        print(f\"Name: {audio_name}, Frame: {frame_idx}, Feature dim: {[f.shape for f in features]}, Label dim: {labels.shape}\")\n",
    "\n",
    "    if i > 300:\n",
    "        break"
   ],
   "id": "2181f2a52c89799a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is what the data looks like:\n",
      "Name: 100300, Frame: 0, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 1, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 2, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 3, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 4, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 5, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 6, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 7, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 8, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 9, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 10, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 11, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 12, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 13, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 14, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 15, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 16, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 17, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 18, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 19, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 20, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 21, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 22, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 23, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 24, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 25, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 26, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 27, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 28, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 29, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 30, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 31, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 32, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 33, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 34, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 35, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 36, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 37, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 38, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 39, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 40, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 41, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 42, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 43, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 44, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 45, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 46, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 47, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 48, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 49, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 50, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 51, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 52, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 53, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 54, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 55, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 56, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 57, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 58, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 59, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 60, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 61, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 62, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 63, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 64, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 65, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 66, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 67, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 68, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 69, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 70, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 71, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 72, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 73, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 74, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 75, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 76, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 77, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 78, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 79, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 80, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 81, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 82, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 83, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 84, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 85, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 86, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 87, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 88, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 89, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 90, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 91, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 92, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 93, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 94, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 95, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 96, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 97, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 98, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 99, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 100, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 101, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 102, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 103, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 104, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 105, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 106, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 107, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 108, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 109, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 110, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 111, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 112, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 113, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 114, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 115, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 116, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 117, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 118, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 119, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 120, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 121, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 122, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 123, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 124, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 125, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 126, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 127, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 128, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 129, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 130, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 131, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 132, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 133, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 134, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 135, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 136, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 137, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 138, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 139, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 140, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 141, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 142, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 143, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 144, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 145, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 146, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 147, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 148, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 149, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 150, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 151, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 152, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 153, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 154, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 155, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 156, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 157, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 158, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 159, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 160, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 161, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 162, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 163, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 164, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 165, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 166, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 167, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 168, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 169, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 170, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 171, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 172, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 173, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 174, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 175, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 176, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 177, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 178, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 179, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 180, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 181, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 182, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 183, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 184, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 185, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 186, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 187, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 188, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 189, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 190, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 191, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 192, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 193, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 194, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 195, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 196, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 197, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 198, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 199, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 200, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 201, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 202, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 203, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 204, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 205, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 206, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 207, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 208, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 209, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 210, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 211, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 212, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 213, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 214, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 215, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 216, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 217, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 218, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 219, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 220, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 0, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 1, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 2, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 3, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 4, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 5, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 6, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 7, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 8, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 9, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 10, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 11, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 12, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 13, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 14, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 15, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 16, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 17, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 18, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 19, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 20, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 21, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 22, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 23, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 24, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 25, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 26, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 27, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 28, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 29, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 30, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 31, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 32, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 33, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 34, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 35, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 36, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 37, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 38, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 39, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 40, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 41, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 42, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 43, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 44, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 45, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 46, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 47, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 48, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 49, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 50, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 51, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 52, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 53, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 54, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 55, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 56, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 57, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 58, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 59, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 60, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 61, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 62, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 63, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 64, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 65, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 66, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 67, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 68, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 69, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 70, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 71, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 72, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 73, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 74, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 75, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 76, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 77, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 78, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 79, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 80, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:03:04.878571Z",
     "start_time": "2025-05-19T10:03:04.871654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_train_test_split(custom_dataset, val_size=0.2, test_size=0.1):\n",
    "    # Creates a dataset split for training, validation and test set, while keeping contents from one file contained in one set,\n",
    "    # like was discussed in the exercise session\n",
    "\n",
    "    n_files = len(custom_dataset.audio_file_basenames)\n",
    "    dataset_size = len(custom_dataset)\n",
    "\n",
    "    if custom_dataset.return_snippets:\n",
    "\n",
    "        # For each file get the index of the first frame\n",
    "        file_start_end_index_dict = {}\n",
    "\n",
    "        for idx, (file_idx, frame_idx, _) in enumerate(custom_dataset.audio_file_labels):\n",
    "            if idx == 0 and frame_idx == 0:\n",
    "                file_start_end_index_dict[file_idx] = [idx, None]\n",
    "            elif idx != 0 and frame_idx == 0:\n",
    "                file_start_end_index_dict[file_idx] = [idx, None]\n",
    "                file_start_end_index_dict[file_idx-1][1] = idx\n",
    "            elif idx == dataset_size - 1:\n",
    "                file_start_end_index_dict[file_idx][1] = idx\n",
    "\n",
    "        # Get indices of files for which to include the snippets in the splits\n",
    "        file_indices = list(range(n_files))\n",
    "        np.random.shuffle(file_indices)\n",
    "        shuffled_file_indices = file_indices\n",
    "\n",
    "        train_size_files = n_files - int(n_files * (val_size + test_size))\n",
    "        val_size_files = int(n_files * val_size)\n",
    "\n",
    "        train_file_indices = shuffled_file_indices[:train_size_files]\n",
    "        val_file_indices = shuffled_file_indices[train_size_files:(train_size_files+val_size_files)]\n",
    "        test_file_indices = shuffled_file_indices[(train_size_files+val_size_files):]\n",
    "\n",
    "        # For each file index in the lists get corresponding indices of the snippets\n",
    "        indices = []\n",
    "        for i, file_indices in enumerate([train_file_indices, val_file_indices, test_file_indices]):\n",
    "            indices.append([])\n",
    "            for file_idx in file_indices:\n",
    "                start_idx, end_idx = file_start_end_index_dict[file_idx]\n",
    "                indices[i].extend(list(range(start_idx, end_idx)))\n",
    "\n",
    "        train_indices = indices[0]\n",
    "        val_indices = indices[1]\n",
    "        test_indices = indices[2]\n",
    "\n",
    "\n",
    "    else: # 1 to 1 correspondence between files and dataset entries\n",
    "        indices = list(range(dataset_size))\n",
    "        np.random.shuffle(indices)\n",
    "        shuffled_indices = indices\n",
    "\n",
    "        train_size = dataset_size - int(dataset_size * (val_size + test_size))\n",
    "        val_size = int(dataset_size * val_size)\n",
    "\n",
    "        train_indices = shuffled_indices[:train_size]\n",
    "        val_indices = shuffled_indices[train_size:(train_size+val_size)]\n",
    "        test_indices = shuffled_indices[(train_size+val_size):]\n",
    "\n",
    "\n",
    "    return train_indices, val_indices, test_indices"
   ],
   "id": "f52d48391c481d4",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:03:05.224444Z",
     "start_time": "2025-05-19T10:03:04.920636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_set, val_set, test_set = custom_train_test_split(data, val_size=0.2, test_size=0.2)\n",
    "print(\"Train, test and validation set sizes:\")\n",
    "print(f\"-Train: {len(train_set)}\")\n",
    "print(f\"-Test: {len(test_set)}\")\n",
    "print(f\"-Validation: {len(val_set)}\")"
   ],
   "id": "ce340bffa1de0ecd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, test and validation set sizes:\n",
      "-Train: 922032\n",
      "-Test: 308509\n",
      "-Validation: 308035\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:03:05.276526Z",
     "start_time": "2025-05-19T10:03:05.273073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get feature dimensions+borders\n",
    "feature_dims = [feature.shape[0] * feature.shape[1] for feature in data[0][3]]\n",
    "total_feature_dim = np.sum(feature_dims, dtype=int)\n",
    "\n",
    "feature_dim_borders = np.cumsum(feature_dims)\n",
    "feature_dim_borders = np.insert(feature_dim_borders, 0, 0)"
   ],
   "id": "6072d965fdf77eb5",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:03:23.267004Z",
     "start_time": "2025-05-19T10:03:05.321679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create data to train and evaluate our models\n",
    "X_train = np.zeros((len(train_set), total_feature_dim))\n",
    "Ys_train = np.zeros((len(train_set), len(all_labels)), dtype=int)\n",
    "for i, idx in enumerate(train_set):\n",
    "    file_idx, audio_name, frame_idx, features, labels = data[idx]\n",
    "    X_train[i] = np.concatenate(features, axis=1).flatten()\n",
    "    labels[labels > 1] = 1\n",
    "    Ys_train[i] = labels\n",
    "    \n",
    "X_val = np.zeros((len(val_set), total_feature_dim))\n",
    "Ys_val = np.zeros((len(val_set), len(all_labels)), dtype=int)\n",
    "for i, idx in enumerate(val_set):\n",
    "    file_idx, audio_name, frame_idx, features, labels = data[idx]\n",
    "    X_val[i] = np.concatenate(features, axis=1).flatten()\n",
    "    labels[labels > 1] = 1\n",
    "    Ys_val[i] = labels\n",
    "\n",
    "X_test = np.zeros((len(test_set), total_feature_dim))\n",
    "Ys_test = np.zeros((len(test_set), len(all_labels)), dtype=int)\n",
    "for i, idx in enumerate(test_set):\n",
    "    file_idx, audio_name, frame_idx, features, labels = data[idx]\n",
    "    X_test[i] = np.concatenate(features, axis=1).flatten()\n",
    "    labels[labels > 1] = 1\n",
    "    Ys_test[i] = labels"
   ],
   "id": "66cbd7f4abeb8dd7",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:08:38.222573Z",
     "start_time": "2025-05-19T10:03:26.106734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Normalize the data using training set statistics (to avoid data leakage)\n",
    "train_mean, train_std = np.mean(X_train, axis=0, keepdims=True), np.std(X_train, axis=0, keepdims=True)\n",
    "\n",
    "X_train = (X_train - train_mean) / train_std\n",
    "X_val = (X_val - train_mean) / train_std\n",
    "X_test = (X_test - train_mean) / train_std"
   ],
   "id": "9984152885bbac3e",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T10:08:38.521855Z",
     "start_time": "2025-05-19T10:08:38.488888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import (f1_score, balanced_accuracy_score)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from time import time\n",
    "import itertools\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED = 42"
   ],
   "id": "46a3e4a36c9a6654",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:58:57.150751Z",
     "start_time": "2025-05-19T18:58:42.564256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Take subset of Dataset for training hyperparameters\n",
    "train_percentage = 0.05\n",
    "X_train_hyperparam = X_train[:int(train_percentage * len(X_train))]\n",
    "X_train_hyperparam = np.insert(X_train_hyperparam, 0, np.zeros(X_train_hyperparam.shape[1]), axis=0)\n",
    "X_train_hyperparam = np.insert(X_train_hyperparam, 0, np.ones(X_train_hyperparam.shape[1]), axis=0)\n",
    "Ys_train_hyperparam = Ys_train[:int(train_percentage * len(Ys_train))]\n",
    "Ys_train_hyperparam = np.insert(Ys_train_hyperparam, 0, np.zeros(Ys_train_hyperparam.shape[1]), axis=0)\n",
    "Ys_train_hyperparam = np.insert(Ys_train_hyperparam, 0, np.ones(Ys_train_hyperparam.shape[1]), axis=0)\n",
    "X_val_hyperparam = X_val[:int(train_percentage * len(X_val))]\n",
    "Ys_val_hyperparam = Ys_val[:int(train_percentage * len(Ys_val))]\n",
    "X_test_hyperparam = X_test[:int(train_percentage * len(X_test))]\n",
    "Ys_test_hyperparam = Ys_test[:int(train_percentage * len(Ys_test))]\n",
    "\n",
    "print(\"Train, test and validation set sizes for tuning the hyperparameters:\")\n",
    "print(f\"-Train: {len(X_train_hyperparam)}\")\n",
    "print(f\"-Test: {len(X_test_hyperparam)}\")\n",
    "print(f\"-Validation: {len(X_val_hyperparam)}\")"
   ],
   "id": "65221e76489e8df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, test and validation set sizes for tuning the hyperparameters:\n",
      "-Train: 461018\n",
      "-Test: 154254\n",
      "-Validation: 154017\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T12:37:14.042328Z",
     "start_time": "2025-05-19T12:37:10.439506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save unseen features for future use\n",
    "np.savez('eval/unseen_features.npz', X_unseen=X_test[:100], Ys_unseen=Ys_test[:100])"
   ],
   "id": "8a57575cb51fa327",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Random Forest",
   "id": "b32e9fb8e4d56d87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:12:39.376067Z",
     "start_time": "2025-05-19T13:51:09.365168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [10, 30, 50],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "best_score = 0\n",
    "best_params_rf = None\n",
    "best_model_rf = None\n",
    "\n",
    "for n_estimators, max_depth, min_samples_split in itertools.product(\n",
    "        param_grid_rf['n_estimators'],\n",
    "        param_grid_rf['max_depth'],\n",
    "        param_grid_rf['min_samples_split'],\n",
    "):\n",
    "    # Initialize the Random Forest classifier\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, random_state=SEED)\n",
    "    model_rf = MultiOutputClassifier(rf, n_jobs=-1)\n",
    "\n",
    "    # Record start time\n",
    "    start_time = time()\n",
    "    # Fit the classifier to the training data\n",
    "    model_rf.fit(X_train_hyperparam, Ys_train_hyperparam)\n",
    "    # Record end time\n",
    "    end_time = time()\n",
    "    # Compute the training time\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Predict class probabilities using the best model\n",
    "    Ys_prediction_val = model_rf.predict(X_val_hyperparam)\n",
    "\n",
    "    f1_scores = []\n",
    "    balanced_accuracy_scores = []\n",
    "    n_labels = len(all_labels)\n",
    "    for i in range(n_labels):\n",
    "        if np.sum(Ys_val_hyperparam[:, i]) == 0: continue # if there is a label with no positive samples -> skip it (can be uncommented but will drag down overall score)\n",
    "\n",
    "        f1 = f1_score(y_true=Ys_val_hyperparam[:, i], y_pred=Ys_prediction_val[:, i], zero_division=0)\n",
    "        ba = balanced_accuracy_score(y_true=Ys_val_hyperparam[:, i], y_pred=Ys_prediction_val[:, i])\n",
    "\n",
    "        f1_scores.append(f1)\n",
    "        balanced_accuracy_scores.append(ba)\n",
    "\n",
    "    # Macro-average across labels\n",
    "    f1_score_macro = np.mean(f1_scores)\n",
    "    balanced_accuracy_score_macro = np.mean(balanced_accuracy_scores)\n",
    "\n",
    "    if f1_score_macro > best_score:\n",
    "        best_score = f1_score_macro\n",
    "        best_params_rf = {\n",
    "            'n_estimators': n_estimators,\n",
    "            'max_depth': max_depth,\n",
    "            'min_samples_split': min_samples_split,\n",
    "            'training_time': training_time,\n",
    "        }\n",
    "        best_model_rf = model_rf\n",
    "\n",
    "        with open('eval/best_params_rf.json', 'w') as f:\n",
    "            json.dump(best_params_rf, f)\n",
    "        joblib.dump(model_rf, \"eval/best_model_rf.pkl\")\n",
    "\n",
    "    print(f\"Hyperparameters: n_estimators={n_estimators}, max_depth={max_depth}, min_samples_split={min_samples_split}\")\n",
    "    print(f\"Macro-Averaged F1 score: {f1_score_macro}\")\n",
    "    print(f\"Macro-Averaged Balanced Accuracy score:{balanced_accuracy_score_macro}\")\n",
    "    print(f\"Training time: {training_time:.4f} seconds\")\n",
    "    print(f\"--------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(best_params_rf)\n",
    "print(f\"Best f1 score: {best_score:.4f}\")"
   ],
   "id": "cebb109207112313",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: n_estimators=10, max_depth=5, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.13505197601047023\n",
      "Macro-Averaged Balanced Accuracy score:0.5518248993837516\n",
      "Training time: 37.9468 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=10, max_depth=5, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.12909364108954866\n",
      "Macro-Averaged Balanced Accuracy score:0.5493703339548076\n",
      "Training time: 38.4227 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=10, max_depth=5, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.12905930458456394\n",
      "Macro-Averaged Balanced Accuracy score:0.5490148523421499\n",
      "Training time: 46.7431 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=10, max_depth=10, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.1985166770072917\n",
      "Macro-Averaged Balanced Accuracy score:0.5738187465720312\n",
      "Training time: 77.5593 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=10, max_depth=10, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.19864142373246377\n",
      "Macro-Averaged Balanced Accuracy score:0.5737001943156131\n",
      "Training time: 81.3601 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=10, max_depth=10, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.1888849737147731\n",
      "Macro-Averaged Balanced Accuracy score:0.5711213196600238\n",
      "Training time: 75.1681 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=10, max_depth=None, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.1674459207860713\n",
      "Macro-Averaged Balanced Accuracy score:0.5609970658308978\n",
      "Training time: 108.7793 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=10, max_depth=None, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.19502313026390572\n",
      "Macro-Averaged Balanced Accuracy score:0.5711198063739652\n",
      "Training time: 112.2785 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=10, max_depth=None, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.18327184738901017\n",
      "Macro-Averaged Balanced Accuracy score:0.5674523590981957\n",
      "Training time: 93.0203 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=5, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.12719955246580145\n",
      "Macro-Averaged Balanced Accuracy score:0.548181544123773\n",
      "Training time: 100.6606 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=5, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.12607806562884613\n",
      "Macro-Averaged Balanced Accuracy score:0.5475638731909974\n",
      "Training time: 102.6797 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=5, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.13068251651981738\n",
      "Macro-Averaged Balanced Accuracy score:0.5492258347406894\n",
      "Training time: 105.4673 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=10, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.18810966749674113\n",
      "Macro-Averaged Balanced Accuracy score:0.571614157287863\n",
      "Training time: 172.7021 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=10, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.1844683688976289\n",
      "Macro-Averaged Balanced Accuracy score:0.569266707884095\n",
      "Training time: 168.4523 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=10, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.17999608351778582\n",
      "Macro-Averaged Balanced Accuracy score:0.5685123763309169\n",
      "Training time: 175.4462 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=None, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.19020437212554442\n",
      "Macro-Averaged Balanced Accuracy score:0.5716189579803989\n",
      "Training time: 248.9957 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=None, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.21603534737921906\n",
      "Macro-Averaged Balanced Accuracy score:0.5815702438359571\n",
      "Training time: 254.4965 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=None, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.19131545822462603\n",
      "Macro-Averaged Balanced Accuracy score:0.5717990314900926\n",
      "Training time: 253.8188 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=5, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.1261230746305323\n",
      "Macro-Averaged Balanced Accuracy score:0.5484836917971503\n",
      "Training time: 161.1412 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=5, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.12497827206722048\n",
      "Macro-Averaged Balanced Accuracy score:0.5477600589058784\n",
      "Training time: 173.3653 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=5, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.128520336211262\n",
      "Macro-Averaged Balanced Accuracy score:0.5493786912664902\n",
      "Training time: 166.5123 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=10, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.17815807823790136\n",
      "Macro-Averaged Balanced Accuracy score:0.5678823016784891\n",
      "Training time: 271.9155 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=10, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.17509057987934523\n",
      "Macro-Averaged Balanced Accuracy score:0.5663156357027019\n",
      "Training time: 263.8499 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=10, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.1671837486985\n",
      "Macro-Averaged Balanced Accuracy score:0.5642152259770693\n",
      "Training time: 265.7159 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=None, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.17952745859967512\n",
      "Macro-Averaged Balanced Accuracy score:0.5683471042738983\n",
      "Training time: 415.8535 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=None, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.19730671994020463\n",
      "Macro-Averaged Balanced Accuracy score:0.5757178482764367\n",
      "Training time: 421.2637 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=None, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.19074136826370486\n",
      "Macro-Averaged Balanced Accuracy score:0.5717964462979139\n",
      "Training time: 448.3492 seconds\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Best Parameters:\n",
      "{'n_estimators': 30, 'max_depth': None, 'min_samples_split': 5, 'training_time': 254.49649810791016}\n",
      "Best f1 score: 0.2160\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:07:58.970581Z",
     "start_time": "2025-05-19T18:07:58.964443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Manually set preferred hyperparameters\n",
    "params_rf = {\n",
    "    'n_estimators': 10,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 5,\n",
    "}\n",
    "\n",
    "with open('eval/best_params_rf.json', 'w') as f:\n",
    "    json.dump(params_rf, f)"
   ],
   "id": "7e2ea1aa99362160",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SVM",
   "id": "d1debfe06463aec3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:06:51.307461Z",
     "start_time": "2025-05-19T17:18:18.172240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'degree': [3],\n",
    "}\n",
    "best_score = 0\n",
    "best_params_svm = None\n",
    "best_model_svm = None\n",
    "\n",
    "for c, kernel, degree in itertools.product(\n",
    "        param_grid_svm['C'],\n",
    "        param_grid_svm['kernel'],\n",
    "        param_grid_svm['degree']):\n",
    "    # Initialize the SVM classifier\n",
    "    svm = SVC(C=c, kernel=kernel, degree=degree, random_state=SEED)\n",
    "    model_svm = MultiOutputClassifier(svm, n_jobs=-1)\n",
    "\n",
    "    # Record start time\n",
    "    start_time = time()\n",
    "    # Fit the classifier to the training data\n",
    "    model_svm.fit(X_train_hyperparam, Ys_train_hyperparam)\n",
    "    # Record end time\n",
    "    end_time = time()\n",
    "    # Compute the training time\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Predict class probabilities using the best model\n",
    "    Ys_prediction_val = model_svm.predict(X_val_hyperparam)\n",
    "\n",
    "    f1_scores = []\n",
    "    balanced_accuracy_scores = []\n",
    "    n_labels = len(all_labels)\n",
    "    for i in range(n_labels):\n",
    "        if np.sum(Ys_val_hyperparam[:, i]) == 0: continue # if there is a label with no positive samples -> skip it (can be uncommented but will drag down overall score)\n",
    "\n",
    "        f1 = f1_score(y_true=Ys_val_hyperparam[:, i], y_pred=Ys_prediction_val[:, i], zero_division=0)\n",
    "        ba = balanced_accuracy_score(y_true=Ys_val_hyperparam[:, i], y_pred=Ys_prediction_val[:, i])\n",
    "\n",
    "        f1_scores.append(f1)\n",
    "        balanced_accuracy_scores.append(ba)\n",
    "\n",
    "    # Macro-average across labels\n",
    "    f1_score_macro = np.mean(f1_scores)\n",
    "    balanced_accuracy_score_macro = np.mean(balanced_accuracy_scores)\n",
    "\n",
    "    if f1_score_macro > best_score:\n",
    "        best_score = f1_score_macro\n",
    "        best_params_svm = {\n",
    "            'C': c,\n",
    "            'kernel': kernel,\n",
    "            'degree': degree,\n",
    "            'training_time': training_time,\n",
    "        }\n",
    "        best_model_svm = model_svm\n",
    "\n",
    "        with open('eval/best_params_svm.json', 'w') as f:\n",
    "            json.dump(best_params_svm, f)\n",
    "        joblib.dump(model_svm, \"eval/best_model_svm.pkl\")\n",
    "\n",
    "    print(f\"Hyperparameters: C={c}, kernel={kernel}, degree={degree}\")\n",
    "    print(f\"Macro-Averaged F1 score: {f1_score_macro}\")\n",
    "    print(f\"Macro-Averaged Balanced Accuracy score:{balanced_accuracy_score_macro}\")\n",
    "    print(f\"Training time: {training_time:.4f} seconds\")\n",
    "    print(f\"--------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(best_params_svm)\n",
    "print(f\"Best f1 score: {best_score:.4f}\")"
   ],
   "id": "74d70fe8c6b4ecc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: C=0.1, kernel=linear, degree=3\n",
      "Macro-Averaged F1 score: 0.362596053931077\n",
      "Macro-Averaged Balanced Accuracy score:0.6763297827756464\n",
      "Training time: 118.0309 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.1, kernel=rbf, degree=3\n",
      "Macro-Averaged F1 score: 0.33763206156541237\n",
      "Macro-Averaged Balanced Accuracy score:0.6384915685275458\n",
      "Training time: 423.9031 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.1, kernel=poly, degree=3\n",
      "Macro-Averaged F1 score: 0.28410347083657017\n",
      "Macro-Averaged Balanced Accuracy score:0.6140138663566099\n",
      "Training time: 643.3794 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=1, kernel=linear, degree=3\n",
      "Macro-Averaged F1 score: 0.35670265473392504\n",
      "Macro-Averaged Balanced Accuracy score:0.6736267378279599\n",
      "Training time: 113.9438 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=1, kernel=rbf, degree=3\n",
      "Macro-Averaged F1 score: 0.37592138118509644\n",
      "Macro-Averaged Balanced Accuracy score:0.6586314187438583\n",
      "Training time: 206.9553 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=1, kernel=poly, degree=3\n",
      "Macro-Averaged F1 score: 0.3121695037329511\n",
      "Macro-Averaged Balanced Accuracy score:0.6262895830181552\n",
      "Training time: 402.9838 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=10, kernel=linear, degree=3\n",
      "Macro-Averaged F1 score: 0.35559776500868934\n",
      "Macro-Averaged Balanced Accuracy score:0.6729021811760862\n",
      "Training time: 119.0574 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=10, kernel=rbf, degree=3\n",
      "Macro-Averaged F1 score: 0.3540999371032167\n",
      "Macro-Averaged Balanced Accuracy score:0.6501979641442215\n",
      "Training time: 171.3777 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=10, kernel=poly, degree=3\n",
      "Macro-Averaged F1 score: 0.32253749283438415\n",
      "Macro-Averaged Balanced Accuracy score:0.6354384350384938\n",
      "Training time: 255.8592 seconds\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Best Parameters:\n",
      "{'C': 1, 'kernel': 'rbf', 'degree': 3, 'training_time': 206.95531296730042}\n",
      "Best f1 score: 0.3759\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Manually set preferred hyperparameters\n",
    "params_svm = {\n",
    "    'C': 10,\n",
    "    'kernel': 10,\n",
    "    'degree': 5,\n",
    "}\n",
    "\n",
    "with open('eval/best_params_svm.json', 'w') as f:\n",
    "    json.dump(params_svm, f)"
   ],
   "id": "a69ea851d249691d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Logistic Regression",
   "id": "5421bcf424b4f00b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T16:46:20.530344Z",
     "start_time": "2025-05-19T16:19:28.709847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid_lg = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2', None],\n",
    "    'solver': ['lbfgs', 'newton-cholesky'],\n",
    "\n",
    "}\n",
    "best_score = 0\n",
    "best_params_lg = None\n",
    "best_model_lg = None\n",
    "\n",
    "for c, penalty, solver in itertools.product(\n",
    "        param_grid_lg['C'],\n",
    "        param_grid_lg['penalty'],\n",
    "        param_grid_lg['solver']):\n",
    "    # Initialize the Logistic Regression classifier\n",
    "    lg = LogisticRegression(C=c, penalty=penalty, solver=solver, random_state=SEED)\n",
    "    model_lg = MultiOutputClassifier(lg, n_jobs=-1)\n",
    "\n",
    "    # Record start time\n",
    "    start_time = time()\n",
    "    # Fit the classifier to the training data\n",
    "    model_lg.fit(X_train_hyperparam, Ys_train_hyperparam)\n",
    "    # Record end time\n",
    "    end_time = time()\n",
    "    # Compute the training time\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Predict class probabilities using the best model\n",
    "    Ys_prediction_val = model_lg.predict(X_val_hyperparam)\n",
    "\n",
    "    f1_scores = []\n",
    "    balanced_accuracy_scores = []\n",
    "    n_labels = len(all_labels)\n",
    "    for i in range(n_labels):\n",
    "        if np.sum(Ys_val_hyperparam[:, i]) == 0: continue # if there is a label with no positive samples -> skip it (can be uncommented but will drag down overall score)\n",
    "\n",
    "        f1 = f1_score(y_true=Ys_val_hyperparam[:, i], y_pred=Ys_prediction_val[:, i], zero_division=0)\n",
    "        ba = balanced_accuracy_score(y_true=Ys_val_hyperparam[:, i], y_pred=Ys_prediction_val[:, i])\n",
    "\n",
    "        f1_scores.append(f1)\n",
    "        balanced_accuracy_scores.append(ba)\n",
    "\n",
    "    # Macro-average across labels\n",
    "    f1_score_macro = np.mean(f1_scores)\n",
    "    balanced_accuracy_score_macro = np.mean(balanced_accuracy_scores)\n",
    "\n",
    "    if f1_score_macro > best_score:\n",
    "        best_score = f1_score_macro\n",
    "        best_params_lg = {\n",
    "            'C': c,\n",
    "            'penalty': penalty,\n",
    "            'solver': solver,\n",
    "            'training_time': training_time,\n",
    "        }\n",
    "        best_model_lg = model_lg\n",
    "\n",
    "        with open('eval/best_params_lg.json', 'w') as f:\n",
    "            json.dump(best_params_lg, f)\n",
    "        joblib.dump(model_lg, \"eval/best_model_lg.pkl\")\n",
    "\n",
    "    print(f\"Hyperparameters: C={c}, penalty={penalty}, solver={solver}\")\n",
    "    print(f\"Macro-Averaged F1 score: {f1_score_macro}\")\n",
    "    print(f\"Macro-Averaged Balanced Accuracy score:{balanced_accuracy_score_macro}\")\n",
    "    print(f\"Training time: {training_time:.4f} seconds\")\n",
    "    print(f\"--------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(best_params_lg)\n",
    "print(f\"Best f1 score: {best_score:.4f}\")\n",
    "\n"
   ],
   "id": "3e1d33152de13199",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: C=0.001, penalty=l2, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.36604950490321353\n",
      "Macro-Averaged Balanced Accuracy score:0.6454835536182414\n",
      "Training time: 38.8272 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.001, penalty=l2, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.3656918301295119\n",
      "Macro-Averaged Balanced Accuracy score:0.6453549896665384\n",
      "Training time: 178.6210 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.001, penalty=None, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 28.2016 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.001, penalty=None, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 49.7649 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.01, penalty=l2, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.38433602324299304\n",
      "Macro-Averaged Balanced Accuracy score:0.6624334498425578\n",
      "Training time: 45.1032 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.01, penalty=l2, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.3834765796460242\n",
      "Macro-Averaged Balanced Accuracy score:0.6611619904855726\n",
      "Training time: 203.2098 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.01, penalty=None, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 28.8756 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.01, penalty=None, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 49.6321 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.1, penalty=l2, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.3913762917192685\n",
      "Macro-Averaged Balanced Accuracy score:0.6787678003834688\n",
      "Training time: 40.4119 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.1, penalty=l2, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.37371589258686616\n",
      "Macro-Averaged Balanced Accuracy score:0.6672628719535799\n",
      "Training time: 204.0704 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.1, penalty=None, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 31.8334 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.1, penalty=None, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 51.4357 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=1, penalty=l2, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.2836678871357738\n",
      "Macro-Averaged Balanced Accuracy score:0.7325246786780211\n",
      "Training time: 32.1399 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=1, penalty=l2, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.3648800805251323\n",
      "Macro-Averaged Balanced Accuracy score:0.6744698464370454\n",
      "Training time: 202.8335 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=1, penalty=None, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 32.1642 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=1, penalty=None, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 52.4832 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=10, penalty=l2, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.26361433678447205\n",
      "Macro-Averaged Balanced Accuracy score:0.7332704065299694\n",
      "Training time: 32.1794 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=10, penalty=l2, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.34368412138454535\n",
      "Macro-Averaged Balanced Accuracy score:0.6840480144731368\n",
      "Training time: 206.7677 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=10, penalty=None, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 33.2953 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=10, penalty=None, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 53.2522 seconds\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Best Parameters:\n",
      "{'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs', 'training_time': 40.41192150115967}\n",
      "Best f1 score: 0.3914\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Manually set preferred hyperparameters\n",
    "params_lg = {\n",
    "    'C': 10,\n",
    "    'penalty': 10,\n",
    "    'solver': 5,\n",
    "}\n",
    "\n",
    "with open('eval/best_params_rf.json', 'w') as f:\n",
    "    json.dump(params_lg, f)"
   ],
   "id": "2ebc8e952d628bfb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train final Models",
   "id": "c4c382d21525efcb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:09:20.231598Z",
     "start_time": "2025-05-19T18:09:20.222680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_final_model(param_grid, classifier='RF'):\n",
    "    if classifier == 'RF':\n",
    "        n_estimators = param_grid['n_estimators']\n",
    "        max_depth = param_grid['max_depth']\n",
    "        min_samples_split = param_grid['min_samples_split']\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, random_state=SEED)\n",
    "        model = MultiOutputClassifier(clf, n_jobs=5)\n",
    "\n",
    "    elif classifier == 'SVM':\n",
    "        c = param_grid['C']\n",
    "        kernel = param_grid['kernel']\n",
    "        degree = param_grid['degree']\n",
    "\n",
    "        clf = SVC(C=c, kernel=kernel, degree=degree, random_state=SEED)\n",
    "        model = MultiOutputClassifier(clf, n_jobs=1)\n",
    "\n",
    "    elif classifier == 'LG':\n",
    "        c = param_grid['C']\n",
    "        penalty = param_grid['penalty']\n",
    "        solver = param_grid['solver']\n",
    "\n",
    "        clf = LogisticRegression(C=c, penalty=penalty, solver=solver, random_state=SEED)\n",
    "        model = MultiOutputClassifier(clf, n_jobs=1)\n",
    "\n",
    "    else:\n",
    "        raise KeyError(\"Invalid classifier name. Please choose one of 'RF', 'SVM', 'LG'.\")\n",
    "\n",
    "    # Record start time\n",
    "    start_time = time()\n",
    "    # Fit the classifier to the training data\n",
    "    model.fit(X_train, Ys_train)\n",
    "    # Record end time\n",
    "    end_time = time()\n",
    "    # Compute the training time\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Predict class probabilities using the best model\n",
    "    Ys_prediction_test = model.predict(X_test)\n",
    "\n",
    "    f1_scores = []\n",
    "    balanced_accuracy_scores = []\n",
    "    n_labels = len(all_labels)\n",
    "    for i in range(n_labels):\n",
    "        if np.sum(Ys_test[:, i]) == 0: continue # if there is a label with no positive samples -> skip it (can be uncommented but will drag down overall score)\n",
    "\n",
    "        f1 = f1_score(y_true=Ys_test[:, i], y_pred=Ys_prediction_test[:, i], zero_division=0)\n",
    "        ba = balanced_accuracy_score(y_true=Ys_test[:, i], y_pred=Ys_prediction_test[:, i])\n",
    "\n",
    "        f1_scores.append(f1)\n",
    "        balanced_accuracy_scores.append(ba)\n",
    "\n",
    "    # Macro-average across labels\n",
    "    f1_score_macro = np.mean(f1_scores)\n",
    "    balanced_accuracy_score_macro = np.mean(balanced_accuracy_scores)\n",
    "\n",
    "    if classifier == 'RF':\n",
    "        joblib.dump(model, \"eval/best_model_rf.pkl\")\n",
    "\n",
    "        print(f\"Hyperparameters: n_estimators={n_estimators}, max_depth={max_depth}, min_samples_split={min_samples_split}\")\n",
    "        print(f\"Macro-Averaged F1 score: {f1_score_macro}\")\n",
    "        print(f\"Macro-Averaged Balanced Accuracy score:{balanced_accuracy_score_macro}\")\n",
    "        print(f\"Training time: {training_time:.4f} seconds\")\n",
    "        print(f\"--------------------------------------------------------------------------\")\n",
    "\n",
    "    elif classifier == 'SVM':\n",
    "        joblib.dump(model, \"eval/best_model_svm.pkl\")\n",
    "\n",
    "        print(f\"Hyperparameters: C={c}, kernel={kernel}, degree={degree}\")\n",
    "        print(f\"Macro-Averaged F1 score: {f1_score_macro}\")\n",
    "        print(f\"Macro-Averaged Balanced Accuracy score:{balanced_accuracy_score_macro}\")\n",
    "        print(f\"Training time: {training_time:.4f} seconds\")\n",
    "        print(f\"--------------------------------------------------------------------------\")\n",
    "\n",
    "    elif classifier == 'LG':\n",
    "        joblib.dump(model, \"eval/best_model_lg.pkl\")\n",
    "\n",
    "        print(f\"Hyperparameters: C={c}, penalty={penalty}, solver={solver}\")\n",
    "        print(f\"Macro-Averaged F1 score: {f1_score_macro}\")\n",
    "        print(f\"Macro-Averaged Balanced Accuracy score:{balanced_accuracy_score_macro}\")\n",
    "        print(f\"Training time: {training_time:.4f} seconds\")\n",
    "        print(f\"--------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "904cc1ab55a1d1fe",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:54:18.988247Z",
     "start_time": "2025-05-19T18:09:22.583225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('eval/best_params_rf.json', 'r') as f:\n",
    "    best_params_rf = json.load(f)\n",
    "\n",
    "train_final_model(best_params_rf, classifier='RF')"
   ],
   "id": "89a3d0d537d5c6c1",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[103], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124meval/best_params_rf.json\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m      2\u001B[0m     best_params_rf \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(f)\n\u001B[1;32m----> 4\u001B[0m train_final_model(best_params_rf, classifier\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRF\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[102], line 32\u001B[0m, in \u001B[0;36mtrain_final_model\u001B[1;34m(param_grid, classifier)\u001B[0m\n\u001B[0;32m     30\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time()\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# Fit the classifier to the training data\u001B[39;00m\n\u001B[1;32m---> 32\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(X_train, Ys_train)\n\u001B[0;32m     33\u001B[0m \u001B[38;5;66;03m# Record end time\u001B[39;00m\n\u001B[0;32m     34\u001B[0m end_time \u001B[38;5;241m=\u001B[39m time()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:543\u001B[0m, in \u001B[0;36mMultiOutputClassifier.fit\u001B[1;34m(self, X, Y, sample_weight, **fit_params)\u001B[0m\n\u001B[0;32m    517\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, Y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params):\n\u001B[0;32m    518\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001B[39;00m\n\u001B[0;32m    519\u001B[0m \n\u001B[0;32m    520\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    541\u001B[0m \u001B[38;5;124;03m        Returns a fitted instance.\u001B[39;00m\n\u001B[0;32m    542\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 543\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mfit(X, Y, sample_weight\u001B[38;5;241m=\u001B[39msample_weight, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m    544\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m=\u001B[39m [estimator\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;28;01mfor\u001B[39;00m estimator \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_]\n\u001B[0;32m    545\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:278\u001B[0m, in \u001B[0;36m_MultiOutputEstimator.fit\u001B[1;34m(self, X, y, sample_weight, **fit_params)\u001B[0m\n\u001B[0;32m    275\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    276\u001B[0m         routed_params\u001B[38;5;241m.\u001B[39mestimator\u001B[38;5;241m.\u001B[39mfit[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msample_weight\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m sample_weight\n\u001B[1;32m--> 278\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_ \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs)(\n\u001B[0;32m    279\u001B[0m     delayed(_fit_estimator)(\n\u001B[0;32m    280\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimator, X, y[:, i], \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mrouted_params\u001B[38;5;241m.\u001B[39mestimator\u001B[38;5;241m.\u001B[39mfit\n\u001B[0;32m    281\u001B[0m     )\n\u001B[0;32m    282\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m    283\u001B[0m )\n\u001B[0;32m    285\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_features_in_\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mn_features_in_\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     69\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     70\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     71\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     73\u001B[0m )\n\u001B[1;32m---> 74\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(iterable_with_config)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   2001\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   2002\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   2003\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[0;32m   2004\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   2005\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 2007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1647\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1649\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1650\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1653\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1654\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1655\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1656\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1757\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1758\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[0;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1760\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1761\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1762\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[0;32m   1763\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1765\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[0;32m   1766\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[0;32m   1767\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open('eval/best_params_svm.json', 'r') as f:\n",
    "    best_params_svm = json.load(f)\n",
    "\n",
    "train_final_model(best_params_svm, classifier='SVM')"
   ],
   "id": "b95fe1f9c0251ae0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open('eval/best_params_lg.json', 'r') as f:\n",
    "    best_params_lg = json.load(f)\n",
    "\n",
    "train_final_model(best_params_lg, classifier='LG')"
   ],
   "id": "3d25bb4f59e8e06"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CNN",
   "id": "c796441c61e17654"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:59:04.686739Z",
     "start_time": "2025-05-19T18:59:04.680871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx]  # Feature tensor\n",
    "        y = self.labels[idx]    # Label tensor\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "train_dataset = AudioDataset(X_train_hyperparam, Ys_train_hyperparam)\n",
    "val_dataset = AudioDataset(X_val_hyperparam, Ys_val_hyperparam)\n",
    "test_dataset = AudioDataset(X_test_hyperparam, Ys_test_hyperparam)\n"
   ],
   "id": "cbb9742d447e23a0",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-19T18:59:06.160879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AudioCNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(AudioCNNClassifier, self).__init__()\n",
    "\n",
    "        # Define 1D Convolutional Layers with Batch Norm\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2)  # Output: (32, 871)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)  # Output: (64, 871)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)  # Output: (128, 871)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)  # Halves sequence length\n",
    "        self.dropout = nn.Dropout(0.3)  # Regularization\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        conv_output_size = input_size // 4  # After 2 max pooling layers\n",
    "        self.fc1 = nn.Linear(128 * conv_output_size, 256)  # Dense layer\n",
    "        self.fc2 = nn.Linear(256, num_classes)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, 1, 871)\n",
    "\n",
    "        # Convolutional Layer 1 with Batch Norm + Activation\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        # Convolutional Layer 2 with Batch Norm + Pooling + Activation\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "\n",
    "        # Convolutional Layer 3 with Batch Norm + Pooling + Activation\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "\n",
    "        x = self.dropout(x)  # Dropout regularization\n",
    "        x = x.view(x.size(0), -1)  # Flatten to feed FC layers\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        x = F.relu(self.fc1(x))  # Fully Connected Layer 1\n",
    "        logits = self.fc2(x)  # Fully Connected Layer 2 (logits)\n",
    "        return logits  # Raw logits for BCEWithLogitsLoss\n",
    "\n",
    "\n",
    "def compute_class_weights(dataset):\n",
    "    # Assumes `dataset` provides labels as a 2D tensor (num_samples x num_classes)\n",
    "    all_labels = torch.cat([labels for _, labels in DataLoader(dataset, batch_size=32)], dim=0).cpu().numpy()\n",
    "    num_classes = all_labels.shape[1]\n",
    "\n",
    "    # Compute class weights for each class\n",
    "    class_weights = []\n",
    "    for class_idx in range(num_classes):\n",
    "        class_weights.append(compute_class_weight('balanced', classes=np.array([0, 1]), y=all_labels[:, class_idx]))\n",
    "\n",
    "    # Convert to tensor\n",
    "    pos_weight = torch.tensor([weights[1] for weights in class_weights], dtype=torch.float32)\n",
    "    return pos_weight\n",
    "\n",
    "\n",
    "def training_loop(\n",
    "        model: torch.nn.Module,\n",
    "        train_data: torch.utils.data.Dataset,\n",
    "        val_data: torch.utils.data.Dataset,\n",
    "        test_data: torch.utils.data.Dataset,\n",
    "        max_epochs: int = 1000,\n",
    "        batch_size: int = 32,\n",
    "        learning_rate: float = 1e-3,\n",
    "        patience: int = 3,\n",
    "        show_progress: bool = True,\n",
    "):\n",
    "    # Set device\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA is available. PyTorch will use the GPU.\")\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA is NOT available. PyTorch will use the CPU.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Compute class weights based on the training dataset\n",
    "    pos_weight = compute_class_weights(train_data).to(device)\n",
    "\n",
    "    # Define loss function with class weights\n",
    "    loss_function = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.1)\n",
    "\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in tqdm(range(max_epochs)) if show_progress else range(max_epochs):\n",
    "        # Training step\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device).unsqueeze(1).float()\n",
    "            labels = labels.to(device).float()\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(inputs)\n",
    "            logits.to(device)\n",
    "            train_loss = loss_function(logits, labels)\n",
    "\n",
    "\n",
    "            total_train_loss += train_loss.item()\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        # Average train loss\n",
    "        train_loss_avg = total_train_loss / len(train_loader)\n",
    "        train_losses.append(train_loss_avg)\n",
    "\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        num_correct = 0\n",
    "        num_total = 0\n",
    "\n",
    "        all_predictions = []\n",
    "        all_true_labels = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device).unsqueeze(1).float()\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # Forward pass\n",
    "                logits = model(inputs)\n",
    "                logits.to(device)\n",
    "                val_loss = loss_function(logits, labels)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "                # Predictions: Threshold sigmoid outputs\n",
    "                predictions = torch.sigmoid(logits) > 0.5  # Threshold at 0.5\n",
    "                num_correct += (predictions == labels).sum().item()\n",
    "                num_total += labels.numel()\n",
    "\n",
    "                # Save predictions and true labels for F1 score calculation\n",
    "                all_predictions.append(predictions.cpu())\n",
    "                all_true_labels.append(labels.cpu())\n",
    "\n",
    "\n",
    "\n",
    "        val_loss_avg = total_val_loss / len(val_loader)\n",
    "        val_losses.append(val_loss_avg)\n",
    "        val_accuracy = 100 * num_correct / num_total\n",
    "\n",
    "        scheduler.step(val_loss_avg)\n",
    "\n",
    "        # Concatenate all batches for F1 score computation\n",
    "        all_predictions = torch.cat(all_predictions).numpy()\n",
    "        all_true_labels = torch.cat(all_true_labels).numpy()\n",
    "\n",
    "        # Calculate the F1 score (macro-averaged for multi-label)\n",
    "        val_f1_score = f1_score(all_true_labels, all_predictions, average='macro', zero_division=0)\n",
    "\n",
    "        # Print metrics for this epoch\n",
    "        print(f\"Epoch [{epoch+1}/{max_epochs}], Train Loss: {train_losses[-1]:.4f}, \"\n",
    "              f\"Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracy:.2f}%, \"\n",
    "              f\"Val F1 Score: {val_f1_score:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "        # Early stopping\n",
    "        if val_losses[-1] < best_val_loss:\n",
    "            best_val_loss = val_losses[-1]\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model_cnn.pth')  # Save best model\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "\n",
    "    # Load best model for testing\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "\n",
    "    # Test set evaluation\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device).unsqueeze(1).float()\n",
    "            labels = labels.to(device).float()\n",
    "            logits = model(inputs)\n",
    "            predictions = torch.sigmoid(logits) > 0.5\n",
    "            num_correct += (predictions == labels).sum().item()\n",
    "            num_total += labels.numel()\n",
    "\n",
    "            # Save predictions and true labels for F1 score calculation\n",
    "            all_predictions.append(predictions.cpu())\n",
    "            all_true_labels.append(labels.cpu())\n",
    "\n",
    "    # Concatenate all batches for F1 score computation\n",
    "    all_predictions = torch.cat(all_predictions).numpy()\n",
    "    all_true_labels = torch.cat(all_true_labels).numpy()\n",
    "\n",
    "    # Calculate the F1 score (macro-averaged for multi-label)\n",
    "    val_f1_score = f1_score(all_true_labels, all_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    test_accuracy = 100 * num_correct / num_total\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%, \"\n",
    "          f\"Test F1 Score: {val_f1_score:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def plot_losses(train_losses, eval_losses):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # Create a new figure with size\n",
    "    ax.set_title(\"Training and Validation Loss over Epochs\")\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Directly use the `train_losses` and `eval_losses` lists if they are floats\n",
    "    ax.plot(train_losses, label=\"Training Loss\")\n",
    "    ax.plot(eval_losses, label=\"Validation Loss\")\n",
    "\n",
    "    # Show the legend and plot\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "model = AudioCNNClassifier(input_size=871, num_classes=len(all_labels))\n",
    "train_losses, eval_losses = training_loop(model, train_dataset, val_dataset, test_dataset,\n",
    "                                          max_epochs=100,\n",
    "                                          learning_rate=1e-3,\n",
    "                                          patience=15,\n",
    "                                          show_progress=True)\n",
    "\n",
    "plot_losses(train_losses, eval_losses)"
   ],
   "id": "81883f813852a65a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. PyTorch will use the GPU.\n",
      "CUDA version: 12.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [01:22<2:16:42, 82.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.0937, Val Loss: 1.3331, Val Accuracy: 97.74%, Val F1 Score: 0.4799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [02:41<2:11:21, 80.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Train Loss: 0.0519, Val Loss: 1.3280, Val Accuracy: 97.85%, Val F1 Score: 0.5064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [04:02<2:10:21, 80.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Train Loss: 0.0489, Val Loss: 1.2863, Val Accuracy: 98.01%, Val F1 Score: 0.5183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [05:21<2:07:58, 79.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Train Loss: 0.0455, Val Loss: 1.1943, Val Accuracy: 97.99%, Val F1 Score: 0.5062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [06:39<2:05:32, 79.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Train Loss: 0.0453, Val Loss: 1.3060, Val Accuracy: 98.08%, Val F1 Score: 0.5145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [07:54<2:02:11, 78.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Train Loss: 0.0448, Val Loss: 1.3926, Val Accuracy: 98.24%, Val F1 Score: 0.5227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [09:14<2:01:33, 78.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Train Loss: 0.0462, Val Loss: 1.2344, Val Accuracy: 98.12%, Val F1 Score: 0.5183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [10:32<2:00:04, 78.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Train Loss: 0.0431, Val Loss: 1.3266, Val Accuracy: 98.11%, Val F1 Score: 0.5169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [11:52<1:59:46, 78.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Train Loss: 0.0431, Val Loss: 1.1767, Val Accuracy: 97.89%, Val F1 Score: 0.5037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [13:13<1:59:26, 79.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss: 0.0441, Val Loss: 1.2667, Val Accuracy: 98.05%, Val F1 Score: 0.5048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [14:38<2:00:27, 81.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Train Loss: 0.0425, Val Loss: 1.2495, Val Accuracy: 97.87%, Val F1 Score: 0.4934\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf639cd1f0d29335"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
