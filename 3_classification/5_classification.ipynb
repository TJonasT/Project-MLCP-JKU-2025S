{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:59:55.422866Z",
     "start_time": "2025-05-21T09:59:45.823583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from random import Random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import sklearn\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import umap.umap_ as umap\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ],
   "id": "b9446b9c9534019a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:59:55.441301Z",
     "start_time": "2025-05-21T09:59:55.434875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Path to the .npz file\n",
    "DATASET_PATH = \"../MLPC2025_classification\"\n",
    "\n",
    "ANNOTATIONS_PATH = DATASET_PATH + \"/annotations.csv\"\n",
    "#ANNOTATIONS_TEXT_EMBEDDINGS_PATH = DATASET_PATH + \"/annotations_text_embeddings.npz\"\n",
    "\n",
    "METADATA_PATH = DATASET_PATH + \"/metadata.csv\"\n",
    "#METADATA_TITLE_EMBEDDINGS_PATH = DATASET_PATH + \"/metadata_title_embeddings.npz\"\n",
    "#METADATA_KEYWORDS_EMBEDDINGS_PATH = DATASET_PATH + \"/metadata_keywords_embeddings.npz\"\n",
    "\n",
    "AUDIO_PATHS = DATASET_PATH + \"/audio\"\n",
    "AUDIO_FEATURES_PATHS = DATASET_PATH + \"/audio_features\"\n",
    "\n",
    "LABELS_PATH = DATASET_PATH + \"/labels\""
   ],
   "id": "6c0431f14c6ff38b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:59:55.600311Z",
     "start_time": "2025-05-21T09:59:55.483312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "annotations = pd.read_csv(ANNOTATIONS_PATH)\n",
    "annotations.head()"
   ],
   "id": "2eadf99a822dc0bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     task_id    filename                                          annotator  \\\n",
       "0  161976549  117126.mp3  1145579747015607221221744067969991550764671773...   \n",
       "1  161976549  117126.mp3  1145579747015607221221744067969991550764671773...   \n",
       "2  161976550  118234.mp3  5022633589939139634134314703519782680423201448...   \n",
       "3  161976550  118234.mp3  5022633589939139634134314703519782680423201448...   \n",
       "4  161976551  119173.mp3  8105077500224920444298835829881210427871190692...   \n",
       "\n",
       "                                                text      onset     offset  \\\n",
       "0  An alarm is ringing loudly and repeatedly nearby.   0.000000  10.503064   \n",
       "1             An alarm is ringing repeatedly nearby.  12.514616  23.048000   \n",
       "2            An alarm clock is beeping continuously.   0.000000  13.414880   \n",
       "3            An alarm clock is beeping continuously.  15.134252  28.492000   \n",
       "4     A car alarm sounds loudly in a steady pattern.   0.000000  20.065604   \n",
       "\n",
       "       time                                   original_caption  \\\n",
       "0   345.033     Raw loud alarm sound repeatedly ringing nearby   \n",
       "1   345.033        Clean alarm sound repeatedly ringing nearby   \n",
       "2   919.016                    Alarm clock beeping continuesly   \n",
       "3   919.016                    Alarm clock beeping continuesly   \n",
       "4  2162.620  a car alarm sounds loudly in a steady pattern ...   \n",
       "\n",
       "                categories  \n",
       "0                ['Alarm']  \n",
       "1                ['Alarm']  \n",
       "2  ['Alarm', 'Beep/Bleep']  \n",
       "3  ['Alarm', 'Beep/Bleep']  \n",
       "4         ['Alarm', 'Car']  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>annotator</th>\n",
       "      <th>text</th>\n",
       "      <th>onset</th>\n",
       "      <th>offset</th>\n",
       "      <th>time</th>\n",
       "      <th>original_caption</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161976549</td>\n",
       "      <td>117126.mp3</td>\n",
       "      <td>1145579747015607221221744067969991550764671773...</td>\n",
       "      <td>An alarm is ringing loudly and repeatedly nearby.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.503064</td>\n",
       "      <td>345.033</td>\n",
       "      <td>Raw loud alarm sound repeatedly ringing nearby</td>\n",
       "      <td>['Alarm']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161976549</td>\n",
       "      <td>117126.mp3</td>\n",
       "      <td>1145579747015607221221744067969991550764671773...</td>\n",
       "      <td>An alarm is ringing repeatedly nearby.</td>\n",
       "      <td>12.514616</td>\n",
       "      <td>23.048000</td>\n",
       "      <td>345.033</td>\n",
       "      <td>Clean alarm sound repeatedly ringing nearby</td>\n",
       "      <td>['Alarm']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>161976550</td>\n",
       "      <td>118234.mp3</td>\n",
       "      <td>5022633589939139634134314703519782680423201448...</td>\n",
       "      <td>An alarm clock is beeping continuously.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.414880</td>\n",
       "      <td>919.016</td>\n",
       "      <td>Alarm clock beeping continuesly</td>\n",
       "      <td>['Alarm', 'Beep/Bleep']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161976550</td>\n",
       "      <td>118234.mp3</td>\n",
       "      <td>5022633589939139634134314703519782680423201448...</td>\n",
       "      <td>An alarm clock is beeping continuously.</td>\n",
       "      <td>15.134252</td>\n",
       "      <td>28.492000</td>\n",
       "      <td>919.016</td>\n",
       "      <td>Alarm clock beeping continuesly</td>\n",
       "      <td>['Alarm', 'Beep/Bleep']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161976551</td>\n",
       "      <td>119173.mp3</td>\n",
       "      <td>8105077500224920444298835829881210427871190692...</td>\n",
       "      <td>A car alarm sounds loudly in a steady pattern.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.065604</td>\n",
       "      <td>2162.620</td>\n",
       "      <td>a car alarm sounds loudly in a steady pattern ...</td>\n",
       "      <td>['Alarm', 'Car']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:59:55.951764Z",
     "start_time": "2025-05-21T09:59:55.931762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove unnecessary columns for this task\n",
    "annotations = annotations.drop(columns=['task_id'])\n",
    "annotations['original_index'] = annotations.index\n",
    "annotations.head()"
   ],
   "id": "97b94e60b45e3b4d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     filename                                          annotator  \\\n",
       "0  117126.mp3  1145579747015607221221744067969991550764671773...   \n",
       "1  117126.mp3  1145579747015607221221744067969991550764671773...   \n",
       "2  118234.mp3  5022633589939139634134314703519782680423201448...   \n",
       "3  118234.mp3  5022633589939139634134314703519782680423201448...   \n",
       "4  119173.mp3  8105077500224920444298835829881210427871190692...   \n",
       "\n",
       "                                                text      onset     offset  \\\n",
       "0  An alarm is ringing loudly and repeatedly nearby.   0.000000  10.503064   \n",
       "1             An alarm is ringing repeatedly nearby.  12.514616  23.048000   \n",
       "2            An alarm clock is beeping continuously.   0.000000  13.414880   \n",
       "3            An alarm clock is beeping continuously.  15.134252  28.492000   \n",
       "4     A car alarm sounds loudly in a steady pattern.   0.000000  20.065604   \n",
       "\n",
       "       time                                   original_caption  \\\n",
       "0   345.033     Raw loud alarm sound repeatedly ringing nearby   \n",
       "1   345.033        Clean alarm sound repeatedly ringing nearby   \n",
       "2   919.016                    Alarm clock beeping continuesly   \n",
       "3   919.016                    Alarm clock beeping continuesly   \n",
       "4  2162.620  a car alarm sounds loudly in a steady pattern ...   \n",
       "\n",
       "                categories  original_index  \n",
       "0                ['Alarm']               0  \n",
       "1                ['Alarm']               1  \n",
       "2  ['Alarm', 'Beep/Bleep']               2  \n",
       "3  ['Alarm', 'Beep/Bleep']               3  \n",
       "4         ['Alarm', 'Car']               4  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>annotator</th>\n",
       "      <th>text</th>\n",
       "      <th>onset</th>\n",
       "      <th>offset</th>\n",
       "      <th>time</th>\n",
       "      <th>original_caption</th>\n",
       "      <th>categories</th>\n",
       "      <th>original_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117126.mp3</td>\n",
       "      <td>1145579747015607221221744067969991550764671773...</td>\n",
       "      <td>An alarm is ringing loudly and repeatedly nearby.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.503064</td>\n",
       "      <td>345.033</td>\n",
       "      <td>Raw loud alarm sound repeatedly ringing nearby</td>\n",
       "      <td>['Alarm']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117126.mp3</td>\n",
       "      <td>1145579747015607221221744067969991550764671773...</td>\n",
       "      <td>An alarm is ringing repeatedly nearby.</td>\n",
       "      <td>12.514616</td>\n",
       "      <td>23.048000</td>\n",
       "      <td>345.033</td>\n",
       "      <td>Clean alarm sound repeatedly ringing nearby</td>\n",
       "      <td>['Alarm']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118234.mp3</td>\n",
       "      <td>5022633589939139634134314703519782680423201448...</td>\n",
       "      <td>An alarm clock is beeping continuously.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.414880</td>\n",
       "      <td>919.016</td>\n",
       "      <td>Alarm clock beeping continuesly</td>\n",
       "      <td>['Alarm', 'Beep/Bleep']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118234.mp3</td>\n",
       "      <td>5022633589939139634134314703519782680423201448...</td>\n",
       "      <td>An alarm clock is beeping continuously.</td>\n",
       "      <td>15.134252</td>\n",
       "      <td>28.492000</td>\n",
       "      <td>919.016</td>\n",
       "      <td>Alarm clock beeping continuesly</td>\n",
       "      <td>['Alarm', 'Beep/Bleep']</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119173.mp3</td>\n",
       "      <td>8105077500224920444298835829881210427871190692...</td>\n",
       "      <td>A car alarm sounds loudly in a steady pattern.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.065604</td>\n",
       "      <td>2162.620</td>\n",
       "      <td>a car alarm sounds loudly in a steady pattern ...</td>\n",
       "      <td>['Alarm', 'Car']</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:59:56.265514Z",
     "start_time": "2025-05-21T09:59:56.152276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metadata = pd.read_csv(METADATA_PATH)\n",
    "metadata.head()"
   ],
   "id": "78e9137d94de8525",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     filename                                           keywords  \\\n",
       "0  321771.mp3      Interior, AMB, Italy, Distant, Speech, Reverb   \n",
       "1  451371.mp3  kids, throaty, crowd, India, distant, traffic,...   \n",
       "2  199414.mp3                           broadcast, speech, radio   \n",
       "3  410952.mp3            loop2017, atmos, dolby, speech, ableton   \n",
       "4  203908.mp3  dr-40, project, speech, student, italian, reci...   \n",
       "\n",
       "   freesound_id                                         sound_link  \\\n",
       "0        321771  https://freesound.org/people/Skjor1/sounds/321...   \n",
       "1        451371  https://freesound.org/people/kyles/sounds/451371/   \n",
       "2        199414  https://freesound.org/people/martinimeniscus/s...   \n",
       "3        410952  https://freesound.org/people/lietoofine/sounds...   \n",
       "4        203908  https://freesound.org/people/s9ames/sounds/203...   \n",
       "\n",
       "      manufacturer                                            license  \\\n",
       "0           Skjor1  http://creativecommons.org/publicdomain/zero/1.0/   \n",
       "1            kyles  http://creativecommons.org/publicdomain/zero/1.0/   \n",
       "2  martinimeniscus  http://creativecommons.org/publicdomain/zero/1.0/   \n",
       "3       lietoofine       https://creativecommons.org/licenses/by/4.0/   \n",
       "4           s9ames        http://creativecommons.org/licenses/by/3.0/   \n",
       "\n",
       "                                               title  \\\n",
       "0  Interior Ambience + Distant Reverberant Speech...   \n",
       "1  election rally crowd and speech with distant t...   \n",
       "2      Old Radio Speech Background, higher FF125.aif   \n",
       "3                             dolby atmos speech.wav   \n",
       "4                            bologna speech Italian2   \n",
       "\n",
       "                                         description  num_downloads  \\\n",
       "0  Interior Ambience + Distant Reverberant Speech...            120   \n",
       "1  election rally crowd and speech with distant t...            122   \n",
       "2  Background noise for an old radio broadcast sp...            391   \n",
       "3                       dolby atmos speech @Loop2017            193   \n",
       "4  recorded with a tascam dr-40 in a sound studio...            526   \n",
       "\n",
       "                geotag  start_time_s  end_time_s  \n",
       "0                  NaN         5.200      27.179  \n",
       "1                  NaN       120.800     144.984  \n",
       "2                  NaN       102.003     130.921  \n",
       "3  52.479543 13.500279        31.330      54.021  \n",
       "4                  NaN        29.200      45.689  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>keywords</th>\n",
       "      <th>freesound_id</th>\n",
       "      <th>sound_link</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>license</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>num_downloads</th>\n",
       "      <th>geotag</th>\n",
       "      <th>start_time_s</th>\n",
       "      <th>end_time_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321771.mp3</td>\n",
       "      <td>Interior, AMB, Italy, Distant, Speech, Reverb</td>\n",
       "      <td>321771</td>\n",
       "      <td>https://freesound.org/people/Skjor1/sounds/321...</td>\n",
       "      <td>Skjor1</td>\n",
       "      <td>http://creativecommons.org/publicdomain/zero/1.0/</td>\n",
       "      <td>Interior Ambience + Distant Reverberant Speech...</td>\n",
       "      <td>Interior Ambience + Distant Reverberant Speech...</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.200</td>\n",
       "      <td>27.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>451371.mp3</td>\n",
       "      <td>kids, throaty, crowd, India, distant, traffic,...</td>\n",
       "      <td>451371</td>\n",
       "      <td>https://freesound.org/people/kyles/sounds/451371/</td>\n",
       "      <td>kyles</td>\n",
       "      <td>http://creativecommons.org/publicdomain/zero/1.0/</td>\n",
       "      <td>election rally crowd and speech with distant t...</td>\n",
       "      <td>election rally crowd and speech with distant t...</td>\n",
       "      <td>122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.800</td>\n",
       "      <td>144.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199414.mp3</td>\n",
       "      <td>broadcast, speech, radio</td>\n",
       "      <td>199414</td>\n",
       "      <td>https://freesound.org/people/martinimeniscus/s...</td>\n",
       "      <td>martinimeniscus</td>\n",
       "      <td>http://creativecommons.org/publicdomain/zero/1.0/</td>\n",
       "      <td>Old Radio Speech Background, higher FF125.aif</td>\n",
       "      <td>Background noise for an old radio broadcast sp...</td>\n",
       "      <td>391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.003</td>\n",
       "      <td>130.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>410952.mp3</td>\n",
       "      <td>loop2017, atmos, dolby, speech, ableton</td>\n",
       "      <td>410952</td>\n",
       "      <td>https://freesound.org/people/lietoofine/sounds...</td>\n",
       "      <td>lietoofine</td>\n",
       "      <td>https://creativecommons.org/licenses/by/4.0/</td>\n",
       "      <td>dolby atmos speech.wav</td>\n",
       "      <td>dolby atmos speech @Loop2017</td>\n",
       "      <td>193</td>\n",
       "      <td>52.479543 13.500279</td>\n",
       "      <td>31.330</td>\n",
       "      <td>54.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203908.mp3</td>\n",
       "      <td>dr-40, project, speech, student, italian, reci...</td>\n",
       "      <td>203908</td>\n",
       "      <td>https://freesound.org/people/s9ames/sounds/203...</td>\n",
       "      <td>s9ames</td>\n",
       "      <td>http://creativecommons.org/licenses/by/3.0/</td>\n",
       "      <td>bologna speech Italian2</td>\n",
       "      <td>recorded with a tascam dr-40 in a sound studio...</td>\n",
       "      <td>526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.200</td>\n",
       "      <td>45.689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:59:56.651617Z",
     "start_time": "2025-05-21T09:59:56.642183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove unnecessary columns for this task\n",
    "metadata = metadata.drop(columns=['freesound_id', 'sound_link', 'manufacturer', 'license', 'num_downloads', 'geotag', 'start_time_s', 'end_time_s'])\n",
    "metadata.head()"
   ],
   "id": "32766047cbbd396e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     filename                                           keywords  \\\n",
       "0  321771.mp3      Interior, AMB, Italy, Distant, Speech, Reverb   \n",
       "1  451371.mp3  kids, throaty, crowd, India, distant, traffic,...   \n",
       "2  199414.mp3                           broadcast, speech, radio   \n",
       "3  410952.mp3            loop2017, atmos, dolby, speech, ableton   \n",
       "4  203908.mp3  dr-40, project, speech, student, italian, reci...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Interior Ambience + Distant Reverberant Speech...   \n",
       "1  election rally crowd and speech with distant t...   \n",
       "2      Old Radio Speech Background, higher FF125.aif   \n",
       "3                             dolby atmos speech.wav   \n",
       "4                            bologna speech Italian2   \n",
       "\n",
       "                                         description  \n",
       "0  Interior Ambience + Distant Reverberant Speech...  \n",
       "1  election rally crowd and speech with distant t...  \n",
       "2  Background noise for an old radio broadcast sp...  \n",
       "3                       dolby atmos speech @Loop2017  \n",
       "4  recorded with a tascam dr-40 in a sound studio...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>keywords</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321771.mp3</td>\n",
       "      <td>Interior, AMB, Italy, Distant, Speech, Reverb</td>\n",
       "      <td>Interior Ambience + Distant Reverberant Speech...</td>\n",
       "      <td>Interior Ambience + Distant Reverberant Speech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>451371.mp3</td>\n",
       "      <td>kids, throaty, crowd, India, distant, traffic,...</td>\n",
       "      <td>election rally crowd and speech with distant t...</td>\n",
       "      <td>election rally crowd and speech with distant t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199414.mp3</td>\n",
       "      <td>broadcast, speech, radio</td>\n",
       "      <td>Old Radio Speech Background, higher FF125.aif</td>\n",
       "      <td>Background noise for an old radio broadcast sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>410952.mp3</td>\n",
       "      <td>loop2017, atmos, dolby, speech, ableton</td>\n",
       "      <td>dolby atmos speech.wav</td>\n",
       "      <td>dolby atmos speech @Loop2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203908.mp3</td>\n",
       "      <td>dr-40, project, speech, student, italian, reci...</td>\n",
       "      <td>bologna speech Italian2</td>\n",
       "      <td>recorded with a tascam dr-40 in a sound studio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Idea for splitting the data:\n",
    "\n",
    "Use some fixed percentages for training, validation, and test sets (e.g., 70% training, 15% validation, 15% test).\n",
    "Then, for each label, ensure that the same percentage of files is allocated to each set. This way, you maintain the label distribution across all sets.\n",
    "\n",
    "Additionally, some resampling (e.g. SMOTE), undersampling (e.g. RUS, TOMEK) or class weighting techniques can be applied to maintain balance during training."
   ],
   "id": "151c42fceaed2691"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:59:56.980108Z",
     "start_time": "2025-05-21T09:59:56.968107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AudioClassificationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, audio_features_subset, return_snippets, context_length, testing, testing_percentage):\n",
    "        \"\"\"\n",
    "        data_dir: Path to the dataset directory\n",
    "        audio_features_subset: List of audio features to be used\n",
    "        return_snippets: If False, return whole files, if True, return snippets of size context_length\n",
    "        context_length: Length of the snippets to be returned (ideally uneven number)\n",
    "        testing: If True, use a small subset of the audio files for testing\n",
    "        \"\"\"\n",
    "\n",
    "        self.return_snippets = return_snippets\n",
    "        self.context_length = context_length\n",
    "\n",
    "        audio_path = os.path.join(data_dir, 'audio')\n",
    "\n",
    "        # For testing purposes, use a smaller subset of the audio files (just copy some audio files from the audio directory\n",
    "        # to a new directory at the same level)\n",
    "        #audio_path = os.path.join(data_dir, 'audio_subset_test')\n",
    "\n",
    "        self.audio_file_basenames = [os.path.splitext(os.path.basename(name))[0] for name in os.listdir(audio_path) if name.endswith('.mp3')]\n",
    "        if testing:\n",
    "            testing_count = int(len(self.audio_file_basenames) * testing_percentage)\n",
    "            self.audio_file_basenames = self.audio_file_basenames[:testing_count] # Use only a small subset of the audio files for testing purposes\n",
    "        \n",
    "        \n",
    "        self.audio_file_features = []\n",
    "        self.audio_file_labels = []\n",
    "\n",
    "        for audio_file_idx, audio_file_basename in enumerate(tqdm(self.audio_file_basenames)):\n",
    "\n",
    "            # Remove unwanted features and store remaining features\n",
    "            audio_features_dict = dict(np.load(os.path.join(data_dir, 'audio_features', audio_file_basename + '.npz')))\n",
    "            audio_features = [audio_features_dict[wanted_feature] for wanted_feature in audio_features_subset]\n",
    "\n",
    "            n_frames = audio_features[0].shape[0]\n",
    "\n",
    "            # store whole file at once\n",
    "            if not self.return_snippets:\n",
    "                self.audio_file_features.append(audio_features)\n",
    "            # store single snippets\n",
    "            else:\n",
    "                # Pad so that edge-frames have context\n",
    "                padding = ((context_length//2, context_length//2), (0, 0))\n",
    "                audio_features = [np.pad(array=feature, pad_width=padding, mode='constant', constant_values=0) for feature in audio_features]\n",
    "\n",
    "                for frame_idx in range(n_frames):\n",
    "                    frame_features = [audio_feature[frame_idx:frame_idx + context_length] for audio_feature in audio_features]\n",
    "                    self.audio_file_features.append((audio_file_idx, frame_idx, frame_features))\n",
    "\n",
    "            # Store labels\n",
    "            audio_labels_dict = dict(np.load(os.path.join(data_dir, 'labels', audio_file_basename + '_labels.npz')))\n",
    "\n",
    "            n_labels = len(audio_labels_dict.keys())\n",
    "            file_labels = np.zeros((n_frames, n_labels))\n",
    "            for i, (label_name, label_values) in enumerate(audio_labels_dict.items()):\n",
    "\n",
    "                # If there are multiple label sets -> multiple annotators\n",
    "                if label_values.shape[1] != 1:\n",
    "                    # Like discussed in the exercise class, we choose one at random\n",
    "                    label_values = label_values[:, np.random.randint(0, label_values.shape[1]), np.newaxis]\n",
    "\n",
    "                file_labels[:, i] = label_values[:, 0]\n",
    "\n",
    "            # store labels for whole file at once\n",
    "            if not self.return_snippets:\n",
    "                self.audio_file_labels.append(file_labels)\n",
    "            # store labels for single snippets\n",
    "            else:\n",
    "                for frame_idx, frame_labels in enumerate(file_labels):\n",
    "                    self.audio_file_labels.append((audio_file_idx, frame_idx, frame_labels))\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.audio_file_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if not self.return_snippets:\n",
    "            return self.audio_file_basenames[idx], self.audio_file_features[idx], self.audio_file_labels[idx]\n",
    "        else:\n",
    "            file_idx, frame_idx, frame_features = self.audio_file_features[idx]\n",
    "            file_idx, frame_idx, frame_labels = self.audio_file_labels[idx]\n",
    "            return file_idx, self.audio_file_basenames[file_idx], frame_idx, frame_features, frame_labels"
   ],
   "id": "8bac6543901df80",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T10:04:33.700022Z",
     "start_time": "2025-05-21T09:59:57.208439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_labels = ['Airplane', 'Alarm', 'Beep/Bleep', 'Bell', 'Bicycle', 'Bird Chirp', 'Bus', 'Car', 'Cat Meow', 'Chainsaw', 'Clapping', 'Cough', 'Cow Moo', 'Cowbell', 'Crying', 'Dog Bark', 'Doorbell', 'Drip', 'Drums', 'Fire', 'Footsteps', 'Guitar', 'Hammer', 'Helicopter', 'Hiccup', 'Horn Honk', 'Horse Neigh', 'Insect Buzz', 'Jackhammer', 'Laughter', 'Lawn Mower', 'Motorcycle', 'Piano', 'Pig Oink', 'Power Drill', 'Power Saw', 'Rain', 'Rooster Crow', 'Saxophone', 'Sewing Machine', 'Sheep/Goat Bleat', 'Ship/Boat', 'Shout', 'Singing', 'Siren', 'Sneeze', 'Snoring', 'Speech', 'Stream/River', 'Thunder', 'Train', 'Truck', 'Trumpet', 'Vacuum Cleaner', 'Violin', 'Washing Machine', 'Waves', 'Wind']\n",
    "\n",
    "all_features = ['embeddings', 'melspectrogram', 'mfcc', 'mfcc_delta', 'mfcc_delta2', 'flatness', 'centroid', 'flux', 'energy', 'power', 'bandwidth', 'contrast', 'zerocrossingrate']\n",
    "\n",
    "data = AudioClassificationDataset(\n",
    "    data_dir = DATASET_PATH,\n",
    "    audio_features_subset = ['embeddings', 'melspectrogram', 'mfcc', 'contrast'],\n",
    "    return_snippets = True,\n",
    "    context_length = 1,\n",
    "    testing = False, # Set to False for full dataset\n",
    "    testing_percentage = 0.5\n",
    ")\n",
    "print(f\"Dataset size: {len(data)}\")"
   ],
   "id": "facfd9e524e0c807",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8230/8230 [04:36<00:00, 29.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1538577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T10:04:33.845423Z",
     "start_time": "2025-05-21T10:04:33.836407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"This is what the data looks like:\")\n",
    "for i, example in enumerate(data):\n",
    "    if not data.return_snippets:\n",
    "        audio_name, features, labels = example\n",
    "        print(f\"Name: {audio_name}, Feature dim: {[f.shape for f in features]}, Label dim: {labels.shape}\")\n",
    "    elif data.return_snippets:\n",
    "        file_idx, audio_name, frame_idx, features, labels = example\n",
    "        print(f\"Name: {audio_name}, Frame: {frame_idx}, Feature dim: {[f.shape for f in features]}, Label dim: {labels.shape}\")\n",
    "\n",
    "    if i > 300:\n",
    "        break"
   ],
   "id": "2181f2a52c89799a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is what the data looks like:\n",
      "Name: 100300, Frame: 0, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 1, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 2, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 3, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 4, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 5, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 6, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 7, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 8, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 9, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 10, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 11, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 12, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 13, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 14, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 15, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 16, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 17, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 18, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 19, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 20, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 21, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 22, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 23, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 24, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 25, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 26, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 27, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 28, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 29, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 30, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 31, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 32, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 33, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 34, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 35, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 36, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 37, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 38, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 39, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 40, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 41, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 42, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 43, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 44, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 45, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 46, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 47, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 48, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 49, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 50, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 51, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 52, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 53, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 54, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 55, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 56, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 57, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 58, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 59, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 60, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 61, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 62, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 63, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 64, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 65, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 66, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 67, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 68, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 69, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 70, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 71, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 72, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 73, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 74, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 75, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 76, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 77, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 78, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 79, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 80, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 81, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 82, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 83, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 84, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 85, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 86, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 87, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 88, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 89, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 90, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 91, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 92, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 93, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 94, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 95, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 96, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 97, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 98, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 99, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 100, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 101, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 102, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 103, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 104, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 105, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 106, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 107, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 108, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 109, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 110, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 111, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 112, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 113, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 114, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 115, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 116, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 117, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 118, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 119, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 120, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 121, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 122, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 123, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 124, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 125, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 126, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 127, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 128, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 129, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 130, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 131, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 132, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 133, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 134, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 135, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 136, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 137, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 138, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 139, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 140, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 141, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 142, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 143, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 144, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 145, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 146, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 147, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 148, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 149, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 150, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 151, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 152, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 153, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 154, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 155, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 156, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 157, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 158, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 159, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 160, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 161, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 162, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 163, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 164, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 165, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 166, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 167, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 168, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 169, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 170, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 171, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 172, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 173, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 174, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 175, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 176, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 177, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 178, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 179, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 180, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 181, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 182, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 183, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 184, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 185, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 186, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 187, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 188, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 189, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 190, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 191, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 192, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 193, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 194, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 195, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 196, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 197, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 198, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 199, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 200, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 201, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 202, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 203, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 204, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 205, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 206, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 207, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 208, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 209, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 210, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 211, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 212, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 213, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 214, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 215, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 216, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 217, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 218, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 219, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100300, Frame: 220, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 0, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 1, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 2, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 3, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 4, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 5, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 6, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 7, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 8, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 9, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 10, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 11, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 12, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 13, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 14, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 15, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 16, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 17, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 18, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 19, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 20, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 21, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 22, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 23, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 24, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 25, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 26, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 27, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 28, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 29, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 30, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 31, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 32, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 33, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 34, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 35, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 36, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 37, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 38, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 39, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 40, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 41, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 42, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 43, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 44, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 45, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 46, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 47, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 48, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 49, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 50, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 51, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 52, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 53, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 54, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 55, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 56, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 57, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 58, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 59, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 60, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 61, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 62, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 63, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 64, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 65, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 66, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 67, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 68, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 69, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 70, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 71, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 72, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 73, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 74, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 75, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 76, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 77, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 78, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 79, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n",
      "Name: 100389, Frame: 80, Feature dim: [(1, 768), (1, 64), (1, 32), (1, 7)], Label dim: (58,)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T10:04:33.987599Z",
     "start_time": "2025-05-21T10:04:33.978460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_train_test_split(custom_dataset, val_size=0.2, test_size=0.1):\n",
    "    # Creates a dataset split for training, validation and test set, while keeping contents from one file contained in one set,\n",
    "    # like was discussed in the exercise session\n",
    "\n",
    "    n_files = len(custom_dataset.audio_file_basenames)\n",
    "    dataset_size = len(custom_dataset)\n",
    "\n",
    "    if custom_dataset.return_snippets:\n",
    "\n",
    "        # For each file get the index of the first frame\n",
    "        file_start_end_index_dict = {}\n",
    "\n",
    "        for idx, (file_idx, frame_idx, _) in enumerate(custom_dataset.audio_file_labels):\n",
    "            if idx == 0 and frame_idx == 0:\n",
    "                file_start_end_index_dict[file_idx] = [idx, None]\n",
    "            elif idx != 0 and frame_idx == 0:\n",
    "                file_start_end_index_dict[file_idx] = [idx, None]\n",
    "                file_start_end_index_dict[file_idx-1][1] = idx\n",
    "            elif idx == dataset_size - 1:\n",
    "                file_start_end_index_dict[file_idx][1] = idx\n",
    "\n",
    "        # Get indices of files for which to include the snippets in the splits\n",
    "        file_indices = list(range(n_files))\n",
    "        np.random.shuffle(file_indices)\n",
    "        shuffled_file_indices = file_indices\n",
    "\n",
    "        train_size_files = n_files - int(n_files * (val_size + test_size))\n",
    "        val_size_files = int(n_files * val_size)\n",
    "\n",
    "        train_file_indices = shuffled_file_indices[:train_size_files]\n",
    "        val_file_indices = shuffled_file_indices[train_size_files:(train_size_files+val_size_files)]\n",
    "        test_file_indices = shuffled_file_indices[(train_size_files+val_size_files):]\n",
    "\n",
    "        # For each file index in the lists get corresponding indices of the snippets\n",
    "        indices = []\n",
    "        for i, file_indices in enumerate([train_file_indices, val_file_indices, test_file_indices]):\n",
    "            indices.append([])\n",
    "            for file_idx in file_indices:\n",
    "                start_idx, end_idx = file_start_end_index_dict[file_idx]\n",
    "                indices[i].extend(list(range(start_idx, end_idx)))\n",
    "\n",
    "        train_indices = indices[0]\n",
    "        val_indices = indices[1]\n",
    "        test_indices = indices[2]\n",
    "\n",
    "\n",
    "    else: # 1 to 1 correspondence between files and dataset entries\n",
    "        indices = list(range(dataset_size))\n",
    "        np.random.shuffle(indices)\n",
    "        shuffled_indices = indices\n",
    "\n",
    "        train_size = dataset_size - int(dataset_size * (val_size + test_size))\n",
    "        val_size = int(dataset_size * val_size)\n",
    "\n",
    "        train_indices = shuffled_indices[:train_size]\n",
    "        val_indices = shuffled_indices[train_size:(train_size+val_size)]\n",
    "        test_indices = shuffled_indices[(train_size+val_size):]\n",
    "\n",
    "\n",
    "    return train_indices, val_indices, test_indices"
   ],
   "id": "f52d48391c481d4",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T10:04:34.514683Z",
     "start_time": "2025-05-21T10:04:34.038859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_set, val_set, test_set = custom_train_test_split(data, val_size=0.2, test_size=0.2)\n",
    "print(\"Train, test and validation set sizes:\")\n",
    "print(f\"-Train: {len(train_set)}\")\n",
    "print(f\"-Test: {len(test_set)}\")\n",
    "print(f\"-Validation: {len(val_set)}\")"
   ],
   "id": "ce340bffa1de0ecd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, test and validation set sizes:\n",
      "-Train: 922032\n",
      "-Test: 308509\n",
      "-Validation: 308035\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T10:04:34.557532Z",
     "start_time": "2025-05-21T10:04:34.552424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get feature dimensions+borders\n",
    "feature_dims = [feature.shape[0] * feature.shape[1] for feature in data[0][3]]\n",
    "total_feature_dim = np.sum(feature_dims, dtype=int)\n",
    "\n",
    "feature_dim_borders = np.cumsum(feature_dims)\n",
    "feature_dim_borders = np.insert(feature_dim_borders, 0, 0)"
   ],
   "id": "6072d965fdf77eb5",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T10:04:50.018476Z",
     "start_time": "2025-05-21T10:04:34.595609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create data to train and evaluate our models\n",
    "X_train = np.zeros((len(train_set), total_feature_dim))\n",
    "Ys_train = np.zeros((len(train_set), len(all_labels)), dtype=int)\n",
    "for i, idx in enumerate(train_set):\n",
    "    file_idx, audio_name, frame_idx, features, labels = data[idx]\n",
    "    X_train[i] = np.concatenate(features, axis=1).flatten()\n",
    "    labels[labels > 1] = 1\n",
    "    Ys_train[i] = labels\n",
    "    \n",
    "X_val = np.zeros((len(val_set), total_feature_dim))\n",
    "Ys_val = np.zeros((len(val_set), len(all_labels)), dtype=int)\n",
    "for i, idx in enumerate(val_set):\n",
    "    file_idx, audio_name, frame_idx, features, labels = data[idx]\n",
    "    X_val[i] = np.concatenate(features, axis=1).flatten()\n",
    "    labels[labels > 1] = 1\n",
    "    Ys_val[i] = labels\n",
    "\n",
    "X_test = np.zeros((len(test_set), total_feature_dim))\n",
    "Ys_test = np.zeros((len(test_set), len(all_labels)), dtype=int)\n",
    "for i, idx in enumerate(test_set):\n",
    "    file_idx, audio_name, frame_idx, features, labels = data[idx]\n",
    "    X_test[i] = np.concatenate(features, axis=1).flatten()\n",
    "    labels[labels > 1] = 1\n",
    "    Ys_test[i] = labels"
   ],
   "id": "66cbd7f4abeb8dd7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T10:07:30.043681Z",
     "start_time": "2025-05-21T10:04:50.041182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "# Normalize the data using training set statistics\n",
    "train_mean, train_std = np.mean(X_train, axis=0, keepdims=True), np.std(X_train, axis=0, keepdims=True)\n",
    "\n",
    "X_train = (X_train - train_mean) / train_std\n",
    "X_val = (X_val - train_mean) / train_std\n",
    "X_test = (X_test - train_mean) / train_std\n",
    "\"\"\"\n",
    "\n",
    "# Normalize each frame by itself\n",
    "for e in range(len(X_train)):\n",
    "    for s in range(len(feature_dim_borders)-1):\n",
    "        start_idx, end_idx = feature_dim_borders[s], feature_dim_borders[s+1]\n",
    "        \n",
    "        feature_mean = np.mean(X_train[e, start_idx:end_idx])\n",
    "        feature_std = np.std(X_train[e, start_idx:end_idx])\n",
    "        \n",
    "        if feature_std == 0:\n",
    "            feature_std = 1e-12\n",
    "        X_train[e, start_idx:end_idx] = (X_train[e, start_idx:end_idx] - feature_mean) / feature_std\n",
    "\n",
    "for e in range(len(X_val)):\n",
    "    for s in range(len(feature_dim_borders)-1):\n",
    "        start_idx, end_idx = feature_dim_borders[s], feature_dim_borders[s+1]\n",
    "        \n",
    "        feature_mean = np.mean(X_val[e, start_idx:end_idx])\n",
    "        feature_std = np.std(X_val[e, start_idx:end_idx])\n",
    "        \n",
    "        if feature_std == 0:\n",
    "            feature_std = 1e-12\n",
    "        X_val[e, start_idx:end_idx] = (X_val[e, start_idx:end_idx] - feature_mean) / feature_std\n",
    "\n",
    "for e in range(len(X_test)):\n",
    "    for s in range(len(feature_dim_borders)-1):\n",
    "        start_idx, end_idx = feature_dim_borders[s], feature_dim_borders[s+1]\n",
    "        \n",
    "        feature_mean = np.mean(X_test[e, start_idx:end_idx])\n",
    "        feature_std = np.std(X_test[e, start_idx:end_idx])\n",
    "        \n",
    "        if feature_std == 0:\n",
    "            feature_std = 1e-12\n",
    "        X_test[e, start_idx:end_idx] = (X_test[e, start_idx:end_idx] - feature_mean) / feature_std"
   ],
   "id": "9984152885bbac3e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T10:07:30.099619Z",
     "start_time": "2025-05-21T10:07:30.089620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import f1_score, balanced_accuracy_score, roc_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from time import time\n",
    "import itertools\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED = 42"
   ],
   "id": "46a3e4a36c9a6654",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T10:07:30.356327Z",
     "start_time": "2025-05-21T10:07:30.159070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Take subset of Dataset for training hyperparameters\n",
    "train_percentage = 0.05\n",
    "X_train_hyperparam = X_train[:int(train_percentage * len(X_train))]\n",
    "X_train_hyperparam = np.insert(X_train_hyperparam, 0, np.zeros(X_train_hyperparam.shape[1]), axis=0)\n",
    "X_train_hyperparam = np.insert(X_train_hyperparam, 0, np.ones(X_train_hyperparam.shape[1]), axis=0)\n",
    "Ys_train_hyperparam = Ys_train[:int(train_percentage * len(Ys_train))]\n",
    "Ys_train_hyperparam = np.insert(Ys_train_hyperparam, 0, np.zeros(Ys_train_hyperparam.shape[1]), axis=0)\n",
    "Ys_train_hyperparam = np.insert(Ys_train_hyperparam, 0, np.ones(Ys_train_hyperparam.shape[1]), axis=0)\n",
    "X_val_hyperparam = X_val[:int(train_percentage * len(X_val))]\n",
    "Ys_val_hyperparam = Ys_val[:int(train_percentage * len(Ys_val))]\n",
    "X_test_hyperparam = X_test[:int(train_percentage * len(X_test))]\n",
    "Ys_test_hyperparam = Ys_test[:int(train_percentage * len(Ys_test))]\n",
    "\n",
    "print(\"Train, test and validation set sizes for tuning the hyperparameters:\")\n",
    "print(f\"-Train: {len(X_train_hyperparam)}\")\n",
    "print(f\"-Test: {len(X_test_hyperparam)}\")\n",
    "print(f\"-Validation: {len(X_val_hyperparam)}\")"
   ],
   "id": "65221e76489e8df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, test and validation set sizes for tuning the hyperparameters:\n",
      "-Train: 46103\n",
      "-Test: 15425\n",
      "-Validation: 15401\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Random Forest",
   "id": "b32e9fb8e4d56d87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:12:39.376067Z",
     "start_time": "2025-05-19T13:51:09.365168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [10, 30, 50],\n",
    "    'max_depth': [5, 10, None],e\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "best_score = 0\n",
    "best_params_rf = None\n",
    "best_model_rf = None\n",
    "\n",
    "for n_estimators, max_depth, min_samples_split in itertools.product(\n",
    "        param_grid_rf['n_estimators'],\n",
    "        param_grid_rf['max_depth'],\n",
    "        param_grid_rf['min_samples_split'],\n",
    "):\n",
    "    # Initialize the Random Forest classifier\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, random_state=SEED)\n",
    "    model_rf = MultiOutputClassifier(rf, n_jobs=-1)\n",
    "\n",
    "    # Record start time\n",
    "    start_time = time()\n",
    "    # Fit the classifier to the training data\n",
    "    model_rf.fit(X_train_hyperparam, Ys_train_hyperparam)\n",
    "    # Record end time\n",
    "    end_time = time()\n",
    "    # Compute the training time\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Predict class probabilities using the best model\n",
    "    Ys_prediction_val = model_rf.predict(X_val_hyperparam)\n",
    "\n",
    "    f1_scores = []\n",
    "    balanced_accuracy_scores = []\n",
    "    n_labels = len(all_labels)\n",
    "    for i in range(n_labels):\n",
    "        if np.sum(Ys_val_hyperparam[:, i]) == 0: continue # if there is a label with no positive samples -> skip it (can be uncommented but will drag down overall score)\n",
    "\n",
    "        f1 = f1_score(y_true=Ys_val_hyperparam[:, i], y_pred=Ys_prediction_val[:, i], zero_division=0)\n",
    "        ba = balanced_accuracy_score(y_true=Ys_val_hyperparam[:, i], y_pred=Ys_prediction_val[:, i])\n",
    "\n",
    "        f1_scores.append(f1)\n",
    "        balanced_accuracy_scores.append(ba)\n",
    "\n",
    "    # Macro-average across labels\n",
    "    f1_score_macro = np.mean(f1_scores)\n",
    "    balanced_accuracy_score_macro = np.mean(balanced_accuracy_scores)\n",
    "\n",
    "    if f1_score_macro > best_score:\n",
    "        best_score = f1_score_macro\n",
    "        best_params_rf = {\n",
    "            'n_estimators': n_estimators,\n",
    "            'max_depth': max_depth,\n",
    "            'min_samples_split': min_samples_split,\n",
    "            'training_time': training_time,\n",
    "        }\n",
    "        best_model_rf = model_rf\n",
    "\n",
    "        with open('eval/best_params_rf.json', 'w') as f:\n",
    "            json.dump(best_params_rf, f)\n",
    "        joblib.dump(model_rf, \"eval/best_model_rf.pkl\")\n",
    "\n",
    "    print(f\"Hyperparameters: n_estimators={n_estimators}, max_depth={max_depth}, min_samples_split={min_samples_split}\")\n",
    "    print(f\"Macro-Averaged F1 score: {f1_score_macro}\")\n",
    "    print(f\"Macro-Averaged Balanced Accuracy score:{balanced_accuracy_score_macro}\")\n",
    "    print(f\"Training time: {training_time:.4f} seconds\")\n",
    "    print(f\"--------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(best_params_rf)\n",
    "print(f\"Best f1 score: {best_score:.4f}\")"
   ],
   "id": "cebb109207112313",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: n_estimators=10, max_depth=5, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.13505197601047023\n",
      "Macro-Averaged Balanced Accuracy score:0.5518248993837516\n",
      "Training time: 37.9468 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=10, max_depth=5, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.12909364108954866\n",
      "Macro-Averaged Balanced Accuracy score:0.5493703339548076\n",
      "Training time: 38.4227 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=10, max_depth=5, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.12905930458456394\n",
      "Macro-Averaged Balanced Accuracy score:0.5490148523421499\n",
      "Training time: 46.7431 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=10, max_depth=10, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.1985166770072917\n",
      "Macro-Averaged Balanced Accuracy score:0.5738187465720312\n",
      "Training time: 77.5593 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=10, max_depth=10, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.19864142373246377\n",
      "Macro-Averaged Balanced Accuracy score:0.5737001943156131\n",
      "Training time: 81.3601 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=10, max_depth=10, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.1888849737147731\n",
      "Macro-Averaged Balanced Accuracy score:0.5711213196600238\n",
      "Training time: 75.1681 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=10, max_depth=None, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.1674459207860713\n",
      "Macro-Averaged Balanced Accuracy score:0.5609970658308978\n",
      "Training time: 108.7793 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=10, max_depth=None, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.19502313026390572\n",
      "Macro-Averaged Balanced Accuracy score:0.5711198063739652\n",
      "Training time: 112.2785 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=10, max_depth=None, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.18327184738901017\n",
      "Macro-Averaged Balanced Accuracy score:0.5674523590981957\n",
      "Training time: 93.0203 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=5, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.12719955246580145\n",
      "Macro-Averaged Balanced Accuracy score:0.548181544123773\n",
      "Training time: 100.6606 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=5, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.12607806562884613\n",
      "Macro-Averaged Balanced Accuracy score:0.5475638731909974\n",
      "Training time: 102.6797 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=5, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.13068251651981738\n",
      "Macro-Averaged Balanced Accuracy score:0.5492258347406894\n",
      "Training time: 105.4673 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=10, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.18810966749674113\n",
      "Macro-Averaged Balanced Accuracy score:0.571614157287863\n",
      "Training time: 172.7021 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=10, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.1844683688976289\n",
      "Macro-Averaged Balanced Accuracy score:0.569266707884095\n",
      "Training time: 168.4523 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=10, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.17999608351778582\n",
      "Macro-Averaged Balanced Accuracy score:0.5685123763309169\n",
      "Training time: 175.4462 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=None, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.19020437212554442\n",
      "Macro-Averaged Balanced Accuracy score:0.5716189579803989\n",
      "Training time: 248.9957 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=None, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.21603534737921906\n",
      "Macro-Averaged Balanced Accuracy score:0.5815702438359571\n",
      "Training time: 254.4965 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=30, max_depth=None, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.19131545822462603\n",
      "Macro-Averaged Balanced Accuracy score:0.5717990314900926\n",
      "Training time: 253.8188 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=5, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.1261230746305323\n",
      "Macro-Averaged Balanced Accuracy score:0.5484836917971503\n",
      "Training time: 161.1412 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=5, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.12497827206722048\n",
      "Macro-Averaged Balanced Accuracy score:0.5477600589058784\n",
      "Training time: 173.3653 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=5, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.128520336211262\n",
      "Macro-Averaged Balanced Accuracy score:0.5493786912664902\n",
      "Training time: 166.5123 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=10, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.17815807823790136\n",
      "Macro-Averaged Balanced Accuracy score:0.5678823016784891\n",
      "Training time: 271.9155 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=10, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.17509057987934523\n",
      "Macro-Averaged Balanced Accuracy score:0.5663156357027019\n",
      "Training time: 263.8499 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=10, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.1671837486985\n",
      "Macro-Averaged Balanced Accuracy score:0.5642152259770693\n",
      "Training time: 265.7159 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=None, min_samples_split=2\n",
      "Macro-Averaged F1 score: 0.17952745859967512\n",
      "Macro-Averaged Balanced Accuracy score:0.5683471042738983\n",
      "Training time: 415.8535 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=None, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.19730671994020463\n",
      "Macro-Averaged Balanced Accuracy score:0.5757178482764367\n",
      "Training time: 421.2637 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: n_estimators=50, max_depth=None, min_samples_split=10\n",
      "Macro-Averaged F1 score: 0.19074136826370486\n",
      "Macro-Averaged Balanced Accuracy score:0.5717964462979139\n",
      "Training time: 448.3492 seconds\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Best Parameters:\n",
      "{'n_estimators': 30, 'max_depth': None, 'min_samples_split': 5, 'training_time': 254.49649810791016}\n",
      "Best f1 score: 0.2160\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:07:58.970581Z",
     "start_time": "2025-05-19T18:07:58.964443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Manually set preferred hyperparameters\n",
    "params_rf = {\n",
    "    'n_estimators': 10,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 5,\n",
    "}\n",
    "\n",
    "with open('eval/best_params_rf.json', 'w') as f:\n",
    "    json.dump(params_rf, f)"
   ],
   "id": "7e2ea1aa99362160",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SVM",
   "id": "d1debfe06463aec3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:06:51.307461Z",
     "start_time": "2025-05-19T17:18:18.172240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'degree': [3],\n",
    "}\n",
    "best_score = 0\n",
    "best_params_svm = None\n",
    "best_model_svm = None\n",
    "\n",
    "for c, kernel, degree in itertools.product(\n",
    "        param_grid_svm['C'],\n",
    "        param_grid_svm['kernel'],\n",
    "        param_grid_svm['degree']):\n",
    "    # Initialize the SVM classifier\n",
    "    svm = SVC(C=c, kernel=kernel, degree=degree, random_state=SEED)\n",
    "    model_svm = MultiOutputClassifier(svm, n_jobs=-1)\n",
    "\n",
    "    # Record start time\n",
    "    start_time = time()\n",
    "    # Fit the classifier to the training data\n",
    "    model_svm.fit(X_train_hyperparam, Ys_train_hyperparam)\n",
    "    # Record end time\n",
    "    end_time = time()\n",
    "    # Compute the training time\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Predict class probabilities using the best model\n",
    "    Ys_prediction_val = model_svm.predict(X_val_hyperparam)\n",
    "\n",
    "    f1_scores = []\n",
    "    balanced_accuracy_scores = []\n",
    "    n_labels = len(all_labels)\n",
    "    for i in range(n_labels):\n",
    "        if np.sum(Ys_val_hyperparam[:, i]) == 0: continue # if there is a label with no positive samples -> skip it (can be uncommented but will drag down overall score)\n",
    "\n",
    "        f1 = f1_score(y_true=Ys_val_hyperparam[:, i], y_pred=Ys_prediction_val[:, i], zero_division=0)\n",
    "        ba = balanced_accuracy_score(y_true=Ys_val_hyperparam[:, i], y_pred=Ys_prediction_val[:, i])\n",
    "\n",
    "        f1_scores.append(f1)\n",
    "        balanced_accuracy_scores.append(ba)\n",
    "\n",
    "    # Macro-average across labels\n",
    "    f1_score_macro = np.mean(f1_scores)\n",
    "    balanced_accuracy_score_macro = np.mean(balanced_accuracy_scores)\n",
    "\n",
    "    if f1_score_macro > best_score:\n",
    "        best_score = f1_score_macro\n",
    "        best_params_svm = {\n",
    "            'C': c,\n",
    "            'kernel': kernel,\n",
    "            'degree': degree,\n",
    "            'training_time': training_time,\n",
    "        }\n",
    "        best_model_svm = model_svm\n",
    "\n",
    "        with open('eval/best_params_svm.json', 'w') as f:\n",
    "            json.dump(best_params_svm, f)\n",
    "        joblib.dump(model_svm, \"eval/best_model_svm.pkl\")\n",
    "\n",
    "    print(f\"Hyperparameters: C={c}, kernel={kernel}, degree={degree}\")\n",
    "    print(f\"Macro-Averaged F1 score: {f1_score_macro}\")\n",
    "    print(f\"Macro-Averaged Balanced Accuracy score:{balanced_accuracy_score_macro}\")\n",
    "    print(f\"Training time: {training_time:.4f} seconds\")\n",
    "    print(f\"--------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(best_params_svm)\n",
    "print(f\"Best f1 score: {best_score:.4f}\")"
   ],
   "id": "74d70fe8c6b4ecc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: C=0.1, kernel=linear, degree=3\n",
      "Macro-Averaged F1 score: 0.362596053931077\n",
      "Macro-Averaged Balanced Accuracy score:0.6763297827756464\n",
      "Training time: 118.0309 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.1, kernel=rbf, degree=3\n",
      "Macro-Averaged F1 score: 0.33763206156541237\n",
      "Macro-Averaged Balanced Accuracy score:0.6384915685275458\n",
      "Training time: 423.9031 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.1, kernel=poly, degree=3\n",
      "Macro-Averaged F1 score: 0.28410347083657017\n",
      "Macro-Averaged Balanced Accuracy score:0.6140138663566099\n",
      "Training time: 643.3794 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=1, kernel=linear, degree=3\n",
      "Macro-Averaged F1 score: 0.35670265473392504\n",
      "Macro-Averaged Balanced Accuracy score:0.6736267378279599\n",
      "Training time: 113.9438 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=1, kernel=rbf, degree=3\n",
      "Macro-Averaged F1 score: 0.37592138118509644\n",
      "Macro-Averaged Balanced Accuracy score:0.6586314187438583\n",
      "Training time: 206.9553 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=1, kernel=poly, degree=3\n",
      "Macro-Averaged F1 score: 0.3121695037329511\n",
      "Macro-Averaged Balanced Accuracy score:0.6262895830181552\n",
      "Training time: 402.9838 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=10, kernel=linear, degree=3\n",
      "Macro-Averaged F1 score: 0.35559776500868934\n",
      "Macro-Averaged Balanced Accuracy score:0.6729021811760862\n",
      "Training time: 119.0574 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=10, kernel=rbf, degree=3\n",
      "Macro-Averaged F1 score: 0.3540999371032167\n",
      "Macro-Averaged Balanced Accuracy score:0.6501979641442215\n",
      "Training time: 171.3777 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=10, kernel=poly, degree=3\n",
      "Macro-Averaged F1 score: 0.32253749283438415\n",
      "Macro-Averaged Balanced Accuracy score:0.6354384350384938\n",
      "Training time: 255.8592 seconds\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Best Parameters:\n",
      "{'C': 1, 'kernel': 'rbf', 'degree': 3, 'training_time': 206.95531296730042}\n",
      "Best f1 score: 0.3759\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T09:36:09.736020Z",
     "start_time": "2025-05-20T09:36:09.712988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Manually set preferred hyperparameters\n",
    "params_svm = {\n",
    "    'C': 0.1,\n",
    "    'kernel': 'linear',\n",
    "    'degree': 3,\n",
    "}\n",
    "\n",
    "with open('eval/best_params_svm.json', 'w') as f:\n",
    "    json.dump(params_svm, f)"
   ],
   "id": "a69ea851d249691d",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Logistic Regression",
   "id": "5421bcf424b4f00b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T16:46:20.530344Z",
     "start_time": "2025-05-19T16:19:28.709847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid_lg = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2', None],\n",
    "    'solver': ['lbfgs', 'newton-cholesky'],\n",
    "\n",
    "}\n",
    "best_score = 0\n",
    "best_params_lg = None\n",
    "best_model_lg = None\n",
    "\n",
    "for c, penalty, solver in itertools.product(\n",
    "        param_grid_lg['C'],\n",
    "        param_grid_lg['penalty'],\n",
    "        param_grid_lg['solver']):\n",
    "    # Initialize the Logistic Regression classifier\n",
    "    lr = LogisticRegression(C=c, penalty=penalty, solver=solver, random_state=SEED)\n",
    "    model_lr = MultiOutputClassifier(lr, n_jobs=-1)\n",
    "\n",
    "    # Record start time\n",
    "    start_time = time()\n",
    "    # Fit the classifier to the training data\n",
    "    model_lr.fit(X_train_hyperparam, Ys_train_hyperparam)\n",
    "    # Record end time\n",
    "    end_time = time()\n",
    "    # Compute the training time\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Predict class probabilities using the best model\n",
    "    Ys_prediction_val = model_lr.predict(X_val_hyperparam)\n",
    "\n",
    "    f1_scores = []\n",
    "    balanced_accuracy_scores = []\n",
    "    n_labels = len(all_labels)\n",
    "    for i in range(n_labels):\n",
    "        if np.sum(Ys_val_hyperparam[:, i]) == 0: continue # if there is a label with no positive samples -> skip it (can be uncommented but will drag down overall score)\n",
    "\n",
    "        f1 = f1_score(y_true=Ys_val_hyperparam[:, i], y_pred=Ys_prediction_val[:, i], zero_division=0)\n",
    "        ba = balanced_accuracy_score(y_true=Ys_val_hyperparam[:, i], y_pred=Ys_prediction_val[:, i])\n",
    "\n",
    "        f1_scores.append(f1)\n",
    "        balanced_accuracy_scores.append(ba)\n",
    "\n",
    "    # Macro-average across labels\n",
    "    f1_score_macro = np.mean(f1_scores)\n",
    "    balanced_accuracy_score_macro = np.mean(balanced_accuracy_scores)\n",
    "\n",
    "    if f1_score_macro > best_score:\n",
    "        best_score = f1_score_macro\n",
    "        best_params_lg = {\n",
    "            'C': c,\n",
    "            'penalty': penalty,\n",
    "            'solver': solver,\n",
    "            'training_time': training_time,\n",
    "        }\n",
    "        best_model_lg = model_lr\n",
    "\n",
    "        with open('eval/best_params_lr.json', 'w') as f:\n",
    "            json.dump(best_params_lg, f)\n",
    "        joblib.dump(model_lr, \"eval/best_model_lr.pkl\")\n",
    "\n",
    "    print(f\"Hyperparameters: C={c}, penalty={penalty}, solver={solver}\")\n",
    "    print(f\"Macro-Averaged F1 score: {f1_score_macro}\")\n",
    "    print(f\"Macro-Averaged Balanced Accuracy score:{balanced_accuracy_score_macro}\")\n",
    "    print(f\"Training time: {training_time:.4f} seconds\")\n",
    "    print(f\"--------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(best_params_lg)\n",
    "print(f\"Best f1 score: {best_score:.4f}\")\n",
    "\n"
   ],
   "id": "3e1d33152de13199",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: C=0.001, penalty=l2, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.36604950490321353\n",
      "Macro-Averaged Balanced Accuracy score:0.6454835536182414\n",
      "Training time: 38.8272 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.001, penalty=l2, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.3656918301295119\n",
      "Macro-Averaged Balanced Accuracy score:0.6453549896665384\n",
      "Training time: 178.6210 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.001, penalty=None, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 28.2016 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.001, penalty=None, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 49.7649 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.01, penalty=l2, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.38433602324299304\n",
      "Macro-Averaged Balanced Accuracy score:0.6624334498425578\n",
      "Training time: 45.1032 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.01, penalty=l2, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.3834765796460242\n",
      "Macro-Averaged Balanced Accuracy score:0.6611619904855726\n",
      "Training time: 203.2098 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.01, penalty=None, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 28.8756 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.01, penalty=None, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 49.6321 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.1, penalty=l2, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.3913762917192685\n",
      "Macro-Averaged Balanced Accuracy score:0.6787678003834688\n",
      "Training time: 40.4119 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.1, penalty=l2, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.37371589258686616\n",
      "Macro-Averaged Balanced Accuracy score:0.6672628719535799\n",
      "Training time: 204.0704 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.1, penalty=None, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 31.8334 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=0.1, penalty=None, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 51.4357 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=1, penalty=l2, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.2836678871357738\n",
      "Macro-Averaged Balanced Accuracy score:0.7325246786780211\n",
      "Training time: 32.1399 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=1, penalty=l2, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.3648800805251323\n",
      "Macro-Averaged Balanced Accuracy score:0.6744698464370454\n",
      "Training time: 202.8335 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=1, penalty=None, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 32.1642 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=1, penalty=None, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 52.4832 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=10, penalty=l2, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.26361433678447205\n",
      "Macro-Averaged Balanced Accuracy score:0.7332704065299694\n",
      "Training time: 32.1794 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=10, penalty=l2, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.34368412138454535\n",
      "Macro-Averaged Balanced Accuracy score:0.6840480144731368\n",
      "Training time: 206.7677 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=10, penalty=None, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 33.2953 seconds\n",
      "--------------------------------------------------------------------------\n",
      "Hyperparameters: C=10, penalty=None, solver=newton-cholesky\n",
      "Macro-Averaged F1 score: 0.2611044391066154\n",
      "Macro-Averaged Balanced Accuracy score:0.7329024784895692\n",
      "Training time: 53.2522 seconds\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Best Parameters:\n",
      "{'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs', 'training_time': 40.41192150115967}\n",
      "Best f1 score: 0.3914\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Manually set preferred hyperparameters\n",
    "params_lg = {\n",
    "    'C': 10,\n",
    "    'penalty': 10,\n",
    "    'solver': 5,\n",
    "}\n",
    "\n",
    "with open('eval/best_params_rf.json', 'w') as f:\n",
    "    json.dump(params_lg, f)"
   ],
   "id": "2ebc8e952d628bfb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train final Models",
   "id": "c4c382d21525efcb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T10:10:54.655361Z",
     "start_time": "2025-05-21T10:10:53.069439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Take subset of Dataset for final training\n",
    "train_percentage = 0.25\n",
    "X_train_final = X_train[:int(train_percentage * len(X_train))]\n",
    "X_train_final = np.insert(X_train_final, 0, np.zeros(X_train_final.shape[1]), axis=0)\n",
    "X_train_final = np.insert(X_train_final, 0, np.ones(X_train_final.shape[1]), axis=0)\n",
    "Ys_train_final = Ys_train[:int(train_percentage * len(Ys_train))]\n",
    "Ys_train_final = np.insert(Ys_train_final, 0, np.zeros(Ys_train_final.shape[1]), axis=0)\n",
    "Ys_train_final = np.insert(Ys_train_final, 0, np.ones(Ys_train_final.shape[1]), axis=0)\n",
    "X_val_final = X_val[:int(train_percentage * len(X_val))]\n",
    "Ys_val_final = Ys_val[:int(train_percentage * len(Ys_val))]\n",
    "X_test_final = X_test[:int(train_percentage * len(X_test))]\n",
    "Ys_test_final = Ys_test[:int(train_percentage * len(Ys_test))]\n",
    "\n",
    "print(\"Train, test and validation set sizes for final training:\")\n",
    "print(f\"-Train: {len(X_train_final)}\")\n",
    "print(f\"-Test: {len(X_test_final)}\")\n",
    "print(f\"-Validation: {len(X_val_final)}\")"
   ],
   "id": "5ad0aaa5ce53ebf6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, test and validation set sizes for final training:\n",
      "-Train: 230510\n",
      "-Test: 77127\n",
      "-Validation: 77008\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T10:11:09.490354Z",
     "start_time": "2025-05-21T10:11:09.478356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_final_model(param_grid, classifier='LR'):\n",
    "    if classifier == 'RF':\n",
    "        n_estimators = param_grid['n_estimators']\n",
    "        max_depth = param_grid['max_depth']\n",
    "        min_samples_split = param_grid['min_samples_split']\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, random_state=SEED)\n",
    "        model = MultiOutputClassifier(clf, n_jobs=2)\n",
    "\n",
    "    elif classifier == 'SVM':\n",
    "        c = param_grid['C']\n",
    "        kernel = param_grid['kernel']\n",
    "        degree = param_grid['degree']\n",
    "\n",
    "        clf = SVC(C=c, kernel=kernel, degree=degree, random_state=SEED)\n",
    "        model = MultiOutputClassifier(clf, n_jobs=2)\n",
    "\n",
    "    elif classifier == 'LR':\n",
    "        c = param_grid['C']\n",
    "        penalty = param_grid['penalty']\n",
    "        solver = param_grid['solver']\n",
    "\n",
    "        clf = LogisticRegression(C=c, penalty=penalty, solver=solver, max_iter=1000, random_state=SEED)\n",
    "        model = MultiOutputClassifier(clf, n_jobs=2)\n",
    "\n",
    "    else:\n",
    "        raise KeyError(\"Invalid classifier name. Please choose one of 'RF', 'SVM', 'LG'.\")\n",
    "\n",
    "    # Record start time\n",
    "    start_time = time()\n",
    "    # Fit the classifier to the training data\n",
    "    model.fit(X_train_final, Ys_train_final)\n",
    "    # Record end time\n",
    "    end_time = time()\n",
    "    # Compute the training time\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Predict class probabilities using the best model\n",
    "    Ys_prediction_test = model.predict(X_test_final)\n",
    "\n",
    "    f1_scores = []\n",
    "    balanced_accuracy_scores = []\n",
    "    n_labels = len(all_labels)\n",
    "    for i in range(n_labels):\n",
    "        if np.sum(Ys_test_final[:, i]) == 0: continue # if there is a label with no positive samples -> skip it (can be uncommented but will drag down overall score)\n",
    "\n",
    "        f1 = f1_score(y_true=Ys_test_final[:, i], y_pred=Ys_prediction_test[:, i], zero_division=0)\n",
    "        ba = balanced_accuracy_score(y_true=Ys_test_final[:, i], y_pred=Ys_prediction_test[:, i])\n",
    "\n",
    "        f1_scores.append(f1)\n",
    "        balanced_accuracy_scores.append(ba)\n",
    "\n",
    "    # Macro-average across labels\n",
    "    f1_score_macro = np.mean(f1_scores)\n",
    "    balanced_accuracy_score_macro = np.mean(balanced_accuracy_scores)\n",
    "\n",
    "    if classifier == 'RF':\n",
    "        joblib.dump(model, \"eval/best_model_rf.pkl\")\n",
    "\n",
    "        print(f\"Hyperparameters: n_estimators={n_estimators}, max_depth={max_depth}, min_samples_split={min_samples_split}\")\n",
    "        print(f\"Macro-Averaged F1 score: {f1_score_macro}\")\n",
    "        print(f\"Macro-Averaged Balanced Accuracy score:{balanced_accuracy_score_macro}\")\n",
    "        print(f\"Training time: {training_time:.4f} seconds\")\n",
    "        print(f\"--------------------------------------------------------------------------\")\n",
    "\n",
    "    elif classifier == 'SVM':\n",
    "        joblib.dump(model, \"eval/best_model_svm.pkl\")\n",
    "\n",
    "        print(f\"Hyperparameters: C={c}, kernel={kernel}, degree={degree}\")\n",
    "        print(f\"Macro-Averaged F1 score: {f1_score_macro}\")\n",
    "        print(f\"Macro-Averaged Balanced Accuracy score:{balanced_accuracy_score_macro}\")\n",
    "        print(f\"Training time: {training_time:.4f} seconds\")\n",
    "        print(f\"--------------------------------------------------------------------------\")\n",
    "\n",
    "    elif classifier == 'LR':\n",
    "        joblib.dump(model, \"eval/best_model_lr.pkl\")\n",
    "\n",
    "        print(f\"Hyperparameters: C={c}, penalty={penalty}, solver={solver}\")\n",
    "        print(f\"Macro-Averaged F1 score: {f1_score_macro}\")\n",
    "        print(f\"Macro-Averaged Balanced Accuracy score:{balanced_accuracy_score_macro}\")\n",
    "        print(f\"Training time: {training_time:.4f} seconds\")\n",
    "        print(f\"--------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "904cc1ab55a1d1fe",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T11:25:59.982907Z",
     "start_time": "2025-05-20T10:45:25.393897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('eval/best_params_rf.json', 'r') as f:\n",
    "    best_params_rf = json.load(f)\n",
    "\n",
    "train_final_model(best_params_rf, classifier='RF')"
   ],
   "id": "89a3d0d537d5c6c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: n_estimators=10, max_depth=10, min_samples_split=5\n",
      "Macro-Averaged F1 score: 0.32175789300957464\n",
      "Macro-Averaged Balanced Accuracy score:0.6174237429453017\n",
      "Training time: 2409.4897 seconds\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T15:36:44.809050Z",
     "start_time": "2025-05-21T10:11:11.624616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('eval/best_params_svm.json', 'r') as f:\n",
    "    best_params_svm = json.load(f)\n",
    "\n",
    "train_final_model(best_params_svm, classifier='SVM')"
   ],
   "id": "b95fe1f9c0251ae0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: C=0.1, kernel=linear, degree=3\n",
      "Macro-Averaged F1 score: 0.45655198997678076\n",
      "Macro-Averaged Balanced Accuracy score:0.7236830805008045\n",
      "Training time: 17754.8316 seconds\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T16:36:56.768197Z",
     "start_time": "2025-05-20T14:47:53.960092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('eval/best_params_lr.json', 'r') as f:\n",
    "    best_params_lr = json.load(f)\n",
    "\n",
    "train_final_model(best_params_lr, classifier='LR')"
   ],
   "id": "3d25bb4f59e8e06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: C=0.1, penalty=l2, solver=lbfgs\n",
      "Macro-Averaged F1 score: 0.5460769902396615\n",
      "Macro-Averaged Balanced Accuracy score:0.758768922996522\n",
      "Training time: 6487.1182 seconds\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CNN",
   "id": "c796441c61e17654"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T14:07:54.386365Z",
     "start_time": "2025-05-20T14:07:54.378283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx]  # Feature tensor\n",
    "        y = self.labels[idx]    # Label tensor\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "train_dataset = AudioDataset(X_train_final, Ys_train_final)\n",
    "val_dataset = AudioDataset(X_val_final, Ys_val_final)\n",
    "test_dataset = AudioDataset(X_test_final, Ys_test_final)\n"
   ],
   "id": "cbb9742d447e23a0",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T14:36:44.449980Z",
     "start_time": "2025-05-20T14:36:44.439185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AudioCNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(AudioCNNClassifier, self).__init__()\n",
    "\n",
    "        # Define 1D Convolutional Layers with Batch Norm\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2)  # Output: (32, 871)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)  # Output: (64, 871)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)  # Output: (128, 871)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)  # Halves sequence length\n",
    "        self.dropout = nn.Dropout(0.5)  # Regularization\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        conv_output_size = input_size // 4  # After 2 max pooling layers\n",
    "        self.fc1 = nn.Linear(128 * conv_output_size, 256)  # Dense layer\n",
    "        self.fc2 = nn.Linear(256, num_classes)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, 1, 871)\n",
    "\n",
    "        # Convolutional Layer 1 with Batch Norm + Activation\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        # Convolutional Layer 2 with Batch Norm + Pooling + Activation\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "\n",
    "        # Convolutional Layer 3 with Batch Norm + Pooling + Activation\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "\n",
    "        x = self.dropout(x)  # Dropout regularization\n",
    "        x = x.view(x.size(0), -1)  # Flatten to feed FC layers\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        x = F.relu(self.fc1(x))  # Fully Connected Layer 1\n",
    "        logits = self.fc2(x)  # Fully Connected Layer 2 (logits)\n",
    "        return logits  # Raw logits for BCEWithLogitsLoss"
   ],
   "id": "b14c338b9bf6e023",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T14:47:00.590368Z",
     "start_time": "2025-05-20T14:36:45.713804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "def compute_class_weights(dataset):\n",
    "    # Assumes `dataset` provides labels as a 2D tensor (num_samples x num_classes)\n",
    "    all_labels = torch.cat([labels for _, labels in DataLoader(dataset, batch_size=32)], dim=0).cpu().numpy()\n",
    "    num_classes = all_labels.shape[1]\n",
    "\n",
    "    # Compute class weights for each class\n",
    "    class_weights = []\n",
    "    for class_idx in range(num_classes):\n",
    "        class_weights.append(compute_class_weight('balanced', classes=np.array([0, 1]), y=all_labels[:, class_idx]))\n",
    "\n",
    "    # Convert to tensor\n",
    "    pos_weight = torch.tensor([weights[1] for weights in class_weights], dtype=torch.float32)\n",
    "    return pos_weight\n",
    "\n",
    "\n",
    "def training_loop(\n",
    "        model: torch.nn.Module,\n",
    "        train_data: torch.utils.data.Dataset,\n",
    "        val_data: torch.utils.data.Dataset,\n",
    "        test_data: torch.utils.data.Dataset,\n",
    "        max_epochs: int = 1000,\n",
    "        batch_size: int = 32,\n",
    "        learning_rate: float = 1e-3,\n",
    "        patience: int = 3,\n",
    "        show_progress: bool = True,\n",
    "):\n",
    "    # Set device\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA is available. PyTorch will use the GPU.\")\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA is NOT available. PyTorch will use the CPU.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Compute class weights based on the training dataset\n",
    "    pos_weight = compute_class_weights(train_data).to(device)\n",
    "\n",
    "    # Define loss function with class weights\n",
    "    loss_function = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.05)\n",
    "\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    dynamic_thresholds = None\n",
    "\n",
    "    for epoch in tqdm(range(max_epochs)) if show_progress else range(max_epochs):\n",
    "        # Training step\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device).unsqueeze(1).float()\n",
    "            labels = labels.to(device).float()\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(inputs)\n",
    "            logits.to(device)\n",
    "            train_loss = loss_function(logits, labels)\n",
    "\n",
    "\n",
    "            total_train_loss += train_loss.item()\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        # Average train loss\n",
    "        train_loss_avg = total_train_loss / len(train_loader)\n",
    "        train_losses.append(train_loss_avg)\n",
    "\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        num_correct = 0\n",
    "        num_total = 0\n",
    "\n",
    "        all_predictions = []\n",
    "        all_true_labels = []\n",
    "        all_logits = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device).unsqueeze(1).float()\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                # Forward pass\n",
    "                logits = model(inputs)\n",
    "                logits.to(device)\n",
    "                val_loss = loss_function(logits, labels)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "                # Save logits and labels for threshold computation\n",
    "                all_logits.append(torch.sigmoid(logits).cpu().numpy())  # Apply sigmoid but don't threshold yet\n",
    "                all_true_labels.append(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "        val_loss_avg = total_val_loss / len(val_loader)\n",
    "        val_losses.append(val_loss_avg)\n",
    "\n",
    "        # Concatenate all logits and true labels for threshold computation\n",
    "        all_logits = np.concatenate(all_logits, axis=0)  # Shape: (num_samples, num_classes)\n",
    "        all_true_labels = np.concatenate(all_true_labels, axis=0)  # Shape: (num_samples, num_classes)\n",
    "\n",
    "        # Compute class-wise optimal thresholds from validation set\n",
    "        thresholds = []\n",
    "        for class_idx in range(all_true_labels.shape[1]):\n",
    "            fpr, tpr, thresh = roc_curve(all_true_labels[:, class_idx], all_logits[:, class_idx])\n",
    "            optimal_idx = np.argmax(tpr - fpr)  # Maximize TPR - FPR\n",
    "            thresholds.append(thresh[optimal_idx])\n",
    "\n",
    "        dynamic_thresholds = np.array(thresholds)  # Save for later use\n",
    "\n",
    "        # Apply dynamic thresholds to calculate validation accuracy and F1 score\n",
    "        val_predictions = all_logits > dynamic_thresholds  # Threshold each class accordingly\n",
    "        num_correct = (val_predictions == all_true_labels).sum()\n",
    "        num_total = all_true_labels.size\n",
    "        val_accuracy = 100 * num_correct / num_total\n",
    "\n",
    "\n",
    "        scheduler.step(val_loss_avg)\n",
    "\n",
    "\n",
    "        # Calculate the F1 score (macro-averaged for multi-label)\n",
    "        val_f1_score = f1_score(all_true_labels, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "        # Print metrics for this epoch\n",
    "        print(f\"Epoch [{epoch+1}/{max_epochs}], Train Loss: {train_losses[-1]:.4f}, \"\n",
    "              f\"Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracy:.2f}%, \"\n",
    "              f\"Val F1 Score: {val_f1_score:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "        # Early stopping\n",
    "        if val_losses[-1] < best_val_loss:\n",
    "            best_val_loss = val_losses[-1]\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'eval/best_model_cnn.pth')  # Save best model\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "\n",
    "    # Load best model for testing\n",
    "    model.load_state_dict(torch.load('eval/best_model.pth'))\n",
    "    model.eval()\n",
    "\n",
    "    # Test set evaluation\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    all_logits = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device).unsqueeze(1).float()\n",
    "            labels = labels.to(device).float()\n",
    "            logits = model(inputs)\n",
    "            all_logits.append(torch.sigmoid(logits).cpu().numpy())\n",
    "            all_true_labels.append(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "    all_logits = np.concatenate(all_logits, axis=0)  # raw sigmoid outputs\n",
    "    all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
    "\n",
    "    # Apply dynamic thresholds\n",
    "    test_predictions = all_logits > dynamic_thresholds  # Use precomputed thresholds\n",
    "    num_correct = (test_predictions == all_true_labels).sum()\n",
    "    num_total = all_true_labels.size\n",
    "    test_accuracy = 100 * num_correct / num_total\n",
    "\n",
    "\n",
    "    # Calculate the F1 score (macro-averaged for multi-label)\n",
    "    val_f1_score = f1_score(all_true_labels, test_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    test_accuracy = 100 * num_correct / num_total\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%, \"\n",
    "          f\"Test F1 Score: {val_f1_score:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def plot_losses(train_losses, eval_losses):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # Create a new figure with size\n",
    "    ax.set_title(\"Training and Validation Loss over Epochs\")\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Directly use the `train_losses` and `eval_losses` lists if they are floats\n",
    "    ax.plot(train_losses, label=\"Training Loss\")\n",
    "    ax.plot(eval_losses, label=\"Validation Loss\")\n",
    "\n",
    "    # Show the legend and plot\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "model = AudioCNNClassifier(input_size=871, num_classes=len(all_labels))\n",
    "train_losses, eval_losses = training_loop(model, train_dataset, val_dataset, test_dataset,\n",
    "                                          max_epochs=100,\n",
    "                                          learning_rate=1e-3,\n",
    "                                          patience=5,\n",
    "                                          batch_size=16,\n",
    "                                          show_progress=True)\n",
    "\n",
    "plot_losses(train_losses, eval_losses)"
   ],
   "id": "81883f813852a65a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. PyTorch will use the GPU.\n",
      "CUDA version: 12.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [04:49<7:56:56, 289.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.2586, Val Loss: 0.5064, Val Accuracy: 90.93%, Val F1 Score: 0.2763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [09:29<7:44:15, 284.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Train Loss: 0.2425, Val Loss: 0.5616, Val Accuracy: 90.43%, Val F1 Score: 0.2756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [09:54<8:05:08, 297.02s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 220\u001B[0m\n\u001B[0;32m    216\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[0;32m    219\u001B[0m model \u001B[38;5;241m=\u001B[39m AudioCNNClassifier(input_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m871\u001B[39m, num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(all_labels))\n\u001B[1;32m--> 220\u001B[0m train_losses, eval_losses \u001B[38;5;241m=\u001B[39m training_loop(model, train_dataset, val_dataset, test_dataset,\n\u001B[0;32m    221\u001B[0m                                           max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m,\n\u001B[0;32m    222\u001B[0m                                           learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-3\u001B[39m,\n\u001B[0;32m    223\u001B[0m                                           patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m,\n\u001B[0;32m    224\u001B[0m                                           batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m,\n\u001B[0;32m    225\u001B[0m                                           show_progress\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    227\u001B[0m plot_losses(train_losses, eval_losses)\n",
      "Cell \u001B[1;32mIn[28], line 82\u001B[0m, in \u001B[0;36mtraining_loop\u001B[1;34m(model, train_data, val_data, test_data, max_epochs, batch_size, learning_rate, patience, show_progress)\u001B[0m\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;66;03m# Gradient clipping\u001B[39;00m\n\u001B[0;32m     80\u001B[0m     torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(model\u001B[38;5;241m.\u001B[39mparameters(), max_norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2.0\u001B[39m)\n\u001B[1;32m---> 82\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     84\u001B[0m \u001B[38;5;66;03m# Average train loss\u001B[39;00m\n\u001B[0;32m     85\u001B[0m train_loss_avg \u001B[38;5;241m=\u001B[39m total_train_loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_loader)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:487\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    482\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    483\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    484\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    485\u001B[0m             )\n\u001B[1;32m--> 487\u001B[0m out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    488\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    490\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     89\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     90\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[1;32m---> 91\u001B[0m     ret \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     93\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:223\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    211\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    213\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[0;32m    214\u001B[0m         group,\n\u001B[0;32m    215\u001B[0m         params_with_grad,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    220\u001B[0m         state_steps,\n\u001B[0;32m    221\u001B[0m     )\n\u001B[1;32m--> 223\u001B[0m     adam(\n\u001B[0;32m    224\u001B[0m         params_with_grad,\n\u001B[0;32m    225\u001B[0m         grads,\n\u001B[0;32m    226\u001B[0m         exp_avgs,\n\u001B[0;32m    227\u001B[0m         exp_avg_sqs,\n\u001B[0;32m    228\u001B[0m         max_exp_avg_sqs,\n\u001B[0;32m    229\u001B[0m         state_steps,\n\u001B[0;32m    230\u001B[0m         amsgrad\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamsgrad\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    231\u001B[0m         has_complex\u001B[38;5;241m=\u001B[39mhas_complex,\n\u001B[0;32m    232\u001B[0m         beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[0;32m    233\u001B[0m         beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[0;32m    234\u001B[0m         lr\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    235\u001B[0m         weight_decay\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight_decay\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    236\u001B[0m         eps\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meps\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    237\u001B[0m         maximize\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    238\u001B[0m         foreach\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mforeach\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    239\u001B[0m         capturable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcapturable\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    240\u001B[0m         differentiable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    241\u001B[0m         fused\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfused\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    242\u001B[0m         grad_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrad_scale\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m    243\u001B[0m         found_inf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m    244\u001B[0m     )\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:154\u001B[0m, in \u001B[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m disabled_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:784\u001B[0m, in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    782\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[1;32m--> 784\u001B[0m func(\n\u001B[0;32m    785\u001B[0m     params,\n\u001B[0;32m    786\u001B[0m     grads,\n\u001B[0;32m    787\u001B[0m     exp_avgs,\n\u001B[0;32m    788\u001B[0m     exp_avg_sqs,\n\u001B[0;32m    789\u001B[0m     max_exp_avg_sqs,\n\u001B[0;32m    790\u001B[0m     state_steps,\n\u001B[0;32m    791\u001B[0m     amsgrad\u001B[38;5;241m=\u001B[39mamsgrad,\n\u001B[0;32m    792\u001B[0m     has_complex\u001B[38;5;241m=\u001B[39mhas_complex,\n\u001B[0;32m    793\u001B[0m     beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[0;32m    794\u001B[0m     beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[0;32m    795\u001B[0m     lr\u001B[38;5;241m=\u001B[39mlr,\n\u001B[0;32m    796\u001B[0m     weight_decay\u001B[38;5;241m=\u001B[39mweight_decay,\n\u001B[0;32m    797\u001B[0m     eps\u001B[38;5;241m=\u001B[39meps,\n\u001B[0;32m    798\u001B[0m     maximize\u001B[38;5;241m=\u001B[39mmaximize,\n\u001B[0;32m    799\u001B[0m     capturable\u001B[38;5;241m=\u001B[39mcapturable,\n\u001B[0;32m    800\u001B[0m     differentiable\u001B[38;5;241m=\u001B[39mdifferentiable,\n\u001B[0;32m    801\u001B[0m     grad_scale\u001B[38;5;241m=\u001B[39mgrad_scale,\n\u001B[0;32m    802\u001B[0m     found_inf\u001B[38;5;241m=\u001B[39mfound_inf,\n\u001B[0;32m    803\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:615\u001B[0m, in \u001B[0;36m_multi_tensor_adam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[0;32m    613\u001B[0m torch\u001B[38;5;241m.\u001B[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001B[0;32m    614\u001B[0m torch\u001B[38;5;241m.\u001B[39m_foreach_add_(exp_avg_sq_sqrt, eps)\n\u001B[1;32m--> 615\u001B[0m torch\u001B[38;5;241m.\u001B[39m_foreach_addcdiv_(\n\u001B[0;32m    616\u001B[0m     device_params, device_exp_avgs, exp_avg_sq_sqrt, step_size  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m    617\u001B[0m )\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf639cd1f0d29335"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
